{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17dfc621",
   "metadata": {},
   "source": [
    "# CcGAN Loaded\n",
    "\n",
    "This notebook is used for loading CcGAN and generating images to `.h5` datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d1100",
   "metadata": {},
   "source": [
    "## Step 1 - Import and Settings\n",
    "\n",
    "Import others' libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e679105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380a083",
   "metadata": {},
   "source": [
    "Import our own libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc0e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7071ff",
   "metadata": {},
   "source": [
    "Set hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300d52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Settings\n",
    "DATA_PATH = \"./datasets/Ra_128_indexed.h5\"\n",
    "GENERATE_DATASETS_DIR = \"./output/generated_datasets\"\n",
    "EMBED_MODELS_DIR = \"./output/embed_models\"\n",
    "CCGAN_MODELS_DIR = \"./output/CcGAN_models\"\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Dataset\n",
    "DATA_SPLIT = \"train\"\n",
    "MIN_LABEL = 1.3\n",
    "MAX_LABEL = 5.2\n",
    "NUM_CHANNELS = 3\n",
    "IMG_SIZE = 128\n",
    "MAX_NUM_IMG_PER_LABEL = 1000\n",
    "MAX_NUM_IMG_PER_LABEL_AFTER_REPLICA = 0\n",
    "SHOW_REAL_IMGS = True\n",
    "VISUALIZE_FAKE_IMAGES = True\n",
    "\n",
    "# Embedding Settings\n",
    "NET_EMBED = \"ResNet34_embed\"\n",
    "DIM_EMBED = 128\n",
    "\n",
    "# Embedding Training Settings\n",
    "BASE_LR_X2Y = 0.01\n",
    "BASE_LR_Y2H = 0.01\n",
    "EPOCH_NET_EMBED = 200\n",
    "RESUME_EPOCH_NET_EMBED = 0\n",
    "EPOCH_NET_Y2H = 500\n",
    "BATCH_SIZE_EMBED = 256\n",
    "\n",
    "# GAN Settings\n",
    "GAN = \"CcGAN\"\n",
    "GAN_ARCH = \"SAGAN\"\n",
    "LOSS_TYPE_GAN = \"hinge\"\n",
    "DIM_GAN = 128\n",
    "CGAN_NUM_CLASSES = 20\n",
    "KERNEL_SIGMA = 0.04697700151079382\n",
    "THRESHOLD_TYPE = \"soft\"\n",
    "KAPPA = 108.73916897823854\n",
    "\n",
    "# GAN Training Settings\n",
    "NITERS_GAN = 60000\n",
    "RESUME_NITERS_GAN = 0\n",
    "SAVE_NITERS_FREQ = 5000\n",
    "LR_G = 1e-4\n",
    "LR_D = 1e-4\n",
    "BATCH_SIZE_DISC = 64\n",
    "BATCH_SIZE_GENE = 64\n",
    "NUM_D_STEPS = 4\n",
    "VISUALIZE_FREQ = 1000\n",
    "NONZERO_SOFT_WEIGHT_THRESHOLD = 1e-3\n",
    "\n",
    "# DiffAugment Settings\n",
    "GAN_DIFFAUGMENT = True\n",
    "GAN_DIFFAUGMENT_POLICY = \"color,translation,cutout\"\n",
    "\n",
    "# Generate Settings\n",
    "NUM_GENERATE = 9192\n",
    "BATCH_SIZE_FOR_GENERATE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf3110",
   "metadata": {},
   "source": [
    "Settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97912ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Seeds\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Paths - From arguments\n",
    "if not os.path.exists(GENERATE_DATASETS_DIR):\n",
    "    os.makedirs(GENERATE_DATASETS_DIR, exist_ok=True)\n",
    "if not os.path.exists(EMBED_MODELS_DIR):\n",
    "    os.makedirs(EMBED_MODELS_DIR, exist_ok=True)\n",
    "if not os.path.exists(CCGAN_MODELS_DIR):\n",
    "    os.makedirs(CCGAN_MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Paths - Embedding\n",
    "EMBED_X2Y_PATH = os.path.join(\n",
    "    EMBED_MODELS_DIR,\n",
    "    f\"embed_x2y_{NET_EMBED}_dim_{DIM_EMBED}_batchSize_{BATCH_SIZE_EMBED}_lr_{BASE_LR_X2Y:.0e}_epoch_{EPOCH_NET_EMBED}_seed_{SEED}.pth\",\n",
    ")\n",
    "Y2H_PATH = os.path.join(\n",
    "    EMBED_MODELS_DIR,\n",
    "    f\"y2h_{NET_EMBED}_dim_{DIM_EMBED}_batchSize_{BATCH_SIZE_EMBED}_lr_{BASE_LR_Y2H:.0e}_epoch_{EPOCH_NET_Y2H}_seed_{SEED}.pth\",\n",
    ")\n",
    "\n",
    "# Paths - CcGAN\n",
    "CCGAN_PATH = os.path.join(\n",
    "    CCGAN_MODELS_DIR,\n",
    "    f\"CcGAN_{GAN_ARCH}_dim_{DIM_GAN}_{IMG_SIZE}_batchSizeG_{BATCH_SIZE_GENE}_batchSizeD_{BATCH_SIZE_DISC}_lrG_{LR_G:.0e}_lrD_{LR_D:.0e}_nIters_{NITERS_GAN}_nDsteps_{NUM_D_STEPS}_{THRESHOLD_TYPE}_{KERNEL_SIGMA:.3f}_{KAPPA:.3f}_loss_{LOSS_TYPE_GAN}_seed_{SEED}.pth\",\n",
    ")\n",
    "\n",
    "# Paths - Generate Dataset\n",
    "GENERATE_DATASETS_PATH = os.path.join(\n",
    "    GENERATE_DATASETS_DIR,\n",
    "    f\"CcGAN_{GAN_ARCH}_dim_{DIM_GAN}_{IMG_SIZE}_batchSizeG_{BATCH_SIZE_GENE}_batchSizeD_{BATCH_SIZE_DISC}_lrG_{LR_G:.0e}_lrD_{LR_D:.0e}_nIters_{NITERS_GAN}_nDsteps_{NUM_D_STEPS}_{THRESHOLD_TYPE}_{KERNEL_SIGMA:.3f}_{KAPPA:.3f}_loss_{LOSS_TYPE_GAN}_seed_{SEED}_in_generate.h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e2965",
   "metadata": {},
   "source": [
    "## Step 2 - Load Pretrained Embedding Models\n",
    "\n",
    "In this step we load `net_embed` and `net_y2h` models to CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b535f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): model_y2h(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (7): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (10): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (13): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if NET_EMBED == \"ResNet18_embed\":\n",
    "    net_embed = ResNet18_embed(dim_embed=DIM_EMBED)\n",
    "elif NET_EMBED == \"ResNet34_embed\":\n",
    "    net_embed = ResNet34_embed(dim_embed=DIM_EMBED)\n",
    "elif NET_EMBED == \"ResNet50_embed\":\n",
    "    net_embed = ResNet50_embed(dim_embed=DIM_EMBED)\n",
    "net_embed = net_embed.to(device)\n",
    "net_embed = nn.DataParallel(net_embed)\n",
    "\n",
    "net_y2h = model_y2h(dim_embed=DIM_EMBED)\n",
    "net_y2h = net_y2h.to(device)\n",
    "net_y2h = nn.DataParallel(net_y2h)\n",
    "\n",
    "## (1). Load net_embed first: x2h+h2y\n",
    "checkpoint = torch.load(EMBED_X2Y_PATH, map_location=device)\n",
    "net_embed.load_state_dict(checkpoint[\"net_state_dict\"])\n",
    "\n",
    "## (2). Load y2h\n",
    "checkpoint = torch.load(Y2H_PATH, map_location=device)\n",
    "net_y2h.load_state_dict(checkpoint[\"net_state_dict\"])\n",
    "\n",
    "net_embed.eval()\n",
    "net_h2y = net_embed.module.h2y\n",
    "net_y2h.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d59c7",
   "metadata": {},
   "source": [
    "## Step 3 - Load CcGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b022ac8",
   "metadata": {},
   "source": [
    "This step loads `netG` from `.pth` file, and switch it to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4284b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CcGAN_SAGAN_Generator(\n",
       "    (snlinear0): Linear(in_features=128, out_features=16384, bias=True)\n",
       "    (block1): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=1024, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=1024, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block2): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=1024, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block3): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=256, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=256, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (self_attn): Self_Attn(\n",
       "      (snconv1x1_theta): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (snconv1x1_phi): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (snconv1x1_g): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (snconv1x1_attn): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (block4): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=256, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=256, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block5): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=64, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=64, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.0001, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (snconv2d1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(CCGAN_PATH, map_location=device)\n",
    "netG = CcGAN_SAGAN_Generator(dim_z=DIM_GAN, dim_embed=DIM_EMBED).to(device)\n",
    "netG = nn.DataParallel(netG)\n",
    "netG.load_state_dict(checkpoint[\"netG_state_dict\"])\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc475dd0",
   "metadata": {},
   "source": [
    "## Step 4 - Generate Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca6825",
   "metadata": {},
   "source": [
    "Define a function to generate a batch of images `generate_batch_images`.\n",
    "\n",
    "Define a function to generate all images `generate_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32948a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_images(labels, start_index, batch_size) -> np.ndarray:\n",
    "\n",
    "    # All fake images stored here\n",
    "    fake_images_ndarray = []\n",
    "\n",
    "    # Labels to generate\n",
    "    if start_index + batch_size > labels.shape[0]:\n",
    "        labels_to_generate_raw = np.array(labels[start_index:])\n",
    "    else:\n",
    "        labels_to_generate_raw = np.array(\n",
    "            labels[start_index : (start_index + batch_size)]\n",
    "        )\n",
    "\n",
    "    # Calculate\n",
    "    labels_to_generate = (labels_to_generate_raw - MIN_LABEL) / (MAX_LABEL - MIN_LABEL)\n",
    "    z = torch.randn(labels_to_generate.shape[0], IMG_SIZE, dtype=torch.float).to(device)\n",
    "    y = torch.from_numpy(labels_to_generate).type(torch.float).reshape(-1, 1).to(device)\n",
    "\n",
    "    # Generate and save fake images\n",
    "    batch_fake_images = netG(z, net_y2h(y))\n",
    "    batch_fake_images = batch_fake_images.detach().cpu()\n",
    "    for j in range(batch_fake_images.shape[0]):\n",
    "        fake_image = batch_fake_images[j].permute(1, 2, 0)\n",
    "        fake_images_ndarray.append(fake_image.numpy())\n",
    "\n",
    "    # Transfer to `numpy.ndarray`\n",
    "    fake_images_ndarray = np.array(fake_images_ndarray)\n",
    "\n",
    "    # Return\n",
    "    return fake_images_ndarray\n",
    "\n",
    "\n",
    "def generate_images(labels) -> np.ndarray:\n",
    "\n",
    "    # Init fake images array\n",
    "    fake_images_ndarray = []\n",
    "\n",
    "    # Loop\n",
    "    start_index = 0\n",
    "    while start_index < labels.shape[0]:\n",
    "        print(\n",
    "            f\"Generating images from index [{start_index}, {min(labels.shape[0], start_index + BATCH_SIZE_FOR_GENERATE) - 1}], range [{labels[start_index]:.3f}, {labels[min(labels.shape[0], start_index + BATCH_SIZE_FOR_GENERATE) - 1]:.3f}].\"\n",
    "        )\n",
    "        fake_images_ndarray.append(\n",
    "            generate_batch_images(labels, start_index, BATCH_SIZE_FOR_GENERATE)\n",
    "        )\n",
    "        start_index += BATCH_SIZE_FOR_GENERATE\n",
    "\n",
    "    # Transfer to `numpy.ndarray`\n",
    "    fake_images_ndarray = np.concatenate(fake_images_ndarray, axis=0)\n",
    "\n",
    "    # Return\n",
    "    return fake_images_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2b7b1",
   "metadata": {},
   "source": [
    "Use function `generate_images` function to generate images. (format: `numpy.ndarray`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d5f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images from index [0, 63], range [1.300, 1.327].\n",
      "Generating images from index [64, 127], range [1.327, 1.354].\n",
      "Generating images from index [128, 191], range [1.354, 1.381].\n",
      "Generating images from index [192, 255], range [1.381, 1.408].\n",
      "Generating images from index [256, 319], range [1.409, 1.435].\n",
      "Generating images from index [320, 383], range [1.436, 1.463].\n",
      "Generating images from index [384, 447], range [1.463, 1.490].\n",
      "Generating images from index [448, 511], range [1.490, 1.517].\n",
      "Generating images from index [512, 575], range [1.517, 1.544].\n",
      "Generating images from index [576, 639], range [1.544, 1.571].\n",
      "Generating images from index [640, 703], range [1.572, 1.598].\n",
      "Generating images from index [704, 767], range [1.599, 1.625].\n",
      "Generating images from index [768, 831], range [1.626, 1.653].\n",
      "Generating images from index [832, 895], range [1.653, 1.680].\n",
      "Generating images from index [896, 959], range [1.680, 1.707].\n",
      "Generating images from index [960, 1023], range [1.707, 1.734].\n",
      "Generating images from index [1024, 1087], range [1.735, 1.761].\n",
      "Generating images from index [1088, 1151], range [1.762, 1.788].\n",
      "Generating images from index [1152, 1215], range [1.789, 1.816].\n",
      "Generating images from index [1216, 1279], range [1.816, 1.843].\n",
      "Generating images from index [1280, 1343], range [1.843, 1.870].\n",
      "Generating images from index [1344, 1407], range [1.870, 1.897].\n",
      "Generating images from index [1408, 1471], range [1.897, 1.924].\n",
      "Generating images from index [1472, 1535], range [1.925, 1.951].\n",
      "Generating images from index [1536, 1599], range [1.952, 1.979].\n",
      "Generating images from index [1600, 1663], range [1.979, 2.006].\n",
      "Generating images from index [1664, 1727], range [2.006, 2.033].\n",
      "Generating images from index [1728, 1791], range [2.033, 2.060].\n",
      "Generating images from index [1792, 1855], range [2.060, 2.087].\n",
      "Generating images from index [1856, 1919], range [2.088, 2.114].\n",
      "Generating images from index [1920, 1983], range [2.115, 2.141].\n",
      "Generating images from index [1984, 2047], range [2.142, 2.169].\n",
      "Generating images from index [2048, 2111], range [2.169, 2.196].\n",
      "Generating images from index [2112, 2175], range [2.196, 2.223].\n",
      "Generating images from index [2176, 2239], range [2.223, 2.250].\n",
      "Generating images from index [2240, 2303], range [2.250, 2.277].\n",
      "Generating images from index [2304, 2367], range [2.278, 2.304].\n",
      "Generating images from index [2368, 2431], range [2.305, 2.332].\n",
      "Generating images from index [2432, 2495], range [2.332, 2.359].\n",
      "Generating images from index [2496, 2559], range [2.359, 2.386].\n",
      "Generating images from index [2560, 2623], range [2.386, 2.413].\n",
      "Generating images from index [2624, 2687], range [2.413, 2.440].\n",
      "Generating images from index [2688, 2751], range [2.441, 2.467].\n",
      "Generating images from index [2752, 2815], range [2.468, 2.494].\n",
      "Generating images from index [2816, 2879], range [2.495, 2.522].\n",
      "Generating images from index [2880, 2943], range [2.522, 2.549].\n",
      "Generating images from index [2944, 3007], range [2.549, 2.576].\n",
      "Generating images from index [3008, 3071], range [2.576, 2.603].\n",
      "Generating images from index [3072, 3135], range [2.604, 2.630].\n",
      "Generating images from index [3136, 3199], range [2.631, 2.657].\n",
      "Generating images from index [3200, 3263], range [2.658, 2.685].\n",
      "Generating images from index [3264, 3327], range [2.685, 2.712].\n",
      "Generating images from index [3328, 3391], range [2.712, 2.739].\n",
      "Generating images from index [3392, 3455], range [2.739, 2.766].\n",
      "Generating images from index [3456, 3519], range [2.766, 2.793].\n",
      "Generating images from index [3520, 3583], range [2.794, 2.820].\n",
      "Generating images from index [3584, 3647], range [2.821, 2.848].\n",
      "Generating images from index [3648, 3711], range [2.848, 2.875].\n",
      "Generating images from index [3712, 3775], range [2.875, 2.902].\n",
      "Generating images from index [3776, 3839], range [2.902, 2.929].\n",
      "Generating images from index [3840, 3903], range [2.929, 2.956].\n",
      "Generating images from index [3904, 3967], range [2.957, 2.983].\n",
      "Generating images from index [3968, 4031], range [2.984, 3.010].\n",
      "Generating images from index [4032, 4095], range [3.011, 3.038].\n",
      "Generating images from index [4096, 4159], range [3.038, 3.065].\n",
      "Generating images from index [4160, 4223], range [3.065, 3.092].\n",
      "Generating images from index [4224, 4287], range [3.092, 3.119].\n",
      "Generating images from index [4288, 4351], range [3.120, 3.146].\n",
      "Generating images from index [4352, 4415], range [3.147, 3.173].\n",
      "Generating images from index [4416, 4479], range [3.174, 3.201].\n",
      "Generating images from index [4480, 4543], range [3.201, 3.228].\n",
      "Generating images from index [4544, 4607], range [3.228, 3.255].\n",
      "Generating images from index [4608, 4671], range [3.255, 3.282].\n",
      "Generating images from index [4672, 4735], range [3.282, 3.309].\n",
      "Generating images from index [4736, 4799], range [3.310, 3.336].\n",
      "Generating images from index [4800, 4863], range [3.337, 3.364].\n",
      "Generating images from index [4864, 4927], range [3.364, 3.391].\n",
      "Generating images from index [4928, 4991], range [3.391, 3.418].\n",
      "Generating images from index [4992, 5055], range [3.418, 3.445].\n",
      "Generating images from index [5056, 5119], range [3.445, 3.472].\n",
      "Generating images from index [5120, 5183], range [3.473, 3.499].\n",
      "Generating images from index [5184, 5247], range [3.500, 3.526].\n",
      "Generating images from index [5248, 5311], range [3.527, 3.554].\n",
      "Generating images from index [5312, 5375], range [3.554, 3.581].\n",
      "Generating images from index [5376, 5439], range [3.581, 3.608].\n",
      "Generating images from index [5440, 5503], range [3.608, 3.635].\n",
      "Generating images from index [5504, 5567], range [3.636, 3.662].\n",
      "Generating images from index [5568, 5631], range [3.663, 3.689].\n",
      "Generating images from index [5632, 5695], range [3.690, 3.717].\n",
      "Generating images from index [5696, 5759], range [3.717, 3.744].\n",
      "Generating images from index [5760, 5823], range [3.744, 3.771].\n",
      "Generating images from index [5824, 5887], range [3.771, 3.798].\n",
      "Generating images from index [5888, 5951], range [3.798, 3.825].\n",
      "Generating images from index [5952, 6015], range [3.826, 3.852].\n",
      "Generating images from index [6016, 6079], range [3.853, 3.879].\n",
      "Generating images from index [6080, 6143], range [3.880, 3.907].\n",
      "Generating images from index [6144, 6207], range [3.907, 3.934].\n",
      "Generating images from index [6208, 6271], range [3.934, 3.961].\n",
      "Generating images from index [6272, 6335], range [3.961, 3.988].\n",
      "Generating images from index [6336, 6399], range [3.989, 4.015].\n",
      "Generating images from index [6400, 6463], range [4.016, 4.042].\n",
      "Generating images from index [6464, 6527], range [4.043, 4.070].\n",
      "Generating images from index [6528, 6591], range [4.070, 4.097].\n",
      "Generating images from index [6592, 6655], range [4.097, 4.124].\n",
      "Generating images from index [6656, 6719], range [4.124, 4.151].\n",
      "Generating images from index [6720, 6783], range [4.151, 4.178].\n",
      "Generating images from index [6784, 6847], range [4.179, 4.205].\n",
      "Generating images from index [6848, 6911], range [4.206, 4.233].\n",
      "Generating images from index [6912, 6975], range [4.233, 4.260].\n",
      "Generating images from index [6976, 7039], range [4.260, 4.287].\n",
      "Generating images from index [7040, 7103], range [4.287, 4.314].\n",
      "Generating images from index [7104, 7167], range [4.314, 4.341].\n",
      "Generating images from index [7168, 7231], range [4.342, 4.368].\n",
      "Generating images from index [7232, 7295], range [4.369, 4.395].\n",
      "Generating images from index [7296, 7359], range [4.396, 4.423].\n",
      "Generating images from index [7360, 7423], range [4.423, 4.450].\n",
      "Generating images from index [7424, 7487], range [4.450, 4.477].\n",
      "Generating images from index [7488, 7551], range [4.477, 4.504].\n",
      "Generating images from index [7552, 7615], range [4.505, 4.531].\n",
      "Generating images from index [7616, 7679], range [4.532, 4.558].\n",
      "Generating images from index [7680, 7743], range [4.559, 4.586].\n",
      "Generating images from index [7744, 7807], range [4.586, 4.613].\n",
      "Generating images from index [7808, 7871], range [4.613, 4.640].\n",
      "Generating images from index [7872, 7935], range [4.640, 4.667].\n",
      "Generating images from index [7936, 7999], range [4.667, 4.694].\n",
      "Generating images from index [8000, 8063], range [4.695, 4.721].\n",
      "Generating images from index [8064, 8127], range [4.722, 4.749].\n",
      "Generating images from index [8128, 8191], range [4.749, 4.776].\n",
      "Generating images from index [8192, 8255], range [4.776, 4.803].\n",
      "Generating images from index [8256, 8319], range [4.803, 4.830].\n",
      "Generating images from index [8320, 8383], range [4.830, 4.857].\n",
      "Generating images from index [8384, 8447], range [4.858, 4.884].\n",
      "Generating images from index [8448, 8511], range [4.885, 4.911].\n",
      "Generating images from index [8512, 8575], range [4.912, 4.939].\n",
      "Generating images from index [8576, 8639], range [4.939, 4.966].\n",
      "Generating images from index [8640, 8703], range [4.966, 4.993].\n",
      "Generating images from index [8704, 8767], range [4.993, 5.020].\n",
      "Generating images from index [8768, 8831], range [5.021, 5.047].\n",
      "Generating images from index [8832, 8895], range [5.048, 5.074].\n",
      "Generating images from index [8896, 8959], range [5.075, 5.102].\n",
      "Generating images from index [8960, 9023], range [5.102, 5.129].\n",
      "Generating images from index [9024, 9087], range [5.129, 5.156].\n",
      "Generating images from index [9088, 9151], range [5.156, 5.183].\n",
      "Generating images from index [9152, 9191], range [5.183, 5.200].\n"
     ]
    }
   ],
   "source": [
    "# Linearly calculate labels\n",
    "labels = np.linspace(MIN_LABEL, MAX_LABEL, num=NUM_GENERATE).astype(float)\n",
    "\n",
    "# Store images `numpy.ndarray`\n",
    "fake_images_ndarray = generate_images(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11b438",
   "metadata": {},
   "source": [
    "Make `.h5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d62938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`.h5` file saved in ./output/generated_datasets/CcGAN_SAGAN_dim_128_128_batchSizeG_64_batchSizeD_64_lrG_1e-04_lrD_1e-04_nIters_60000_nDsteps_4_soft_0.047_108.739_loss_hinge_seed_42_in_generate.h5.\n"
     ]
    }
   ],
   "source": [
    "# Convert all images to [0, 255] uint8 and clip values\n",
    "fake_images_ndarray = np.clip((fake_images_ndarray * 0.5 + 0.5) * 255, 0, 255).astype(\n",
    "    \"uint8\"\n",
    ")\n",
    "\n",
    "with h5py.File(GENERATE_DATASETS_PATH, \"w\") as f:\n",
    "    f.create_dataset(\"images\", data=fake_images_ndarray, dtype=\"uint8\")\n",
    "    f.create_dataset(\"index_train\", data=list(range(0, NUM_GENERATE, 2)), dtype=\"int64\")\n",
    "    f.create_dataset(\"index_valid\", data=list(range(1, NUM_GENERATE, 2)), dtype=\"int64\")\n",
    "    f.create_dataset(\"labels\", data=labels, dtype=\"float64\")\n",
    "    f.create_dataset(\"types\", data=np.zeros(NUM_GENERATE, dtype=\"int32\"), dtype=\"int32\")\n",
    "print(f\"`.h5` file saved in {GENERATE_DATASETS_PATH}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68ca77",
   "metadata": {},
   "source": [
    "Use function `view_dataset` to check the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d73316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] images shape=(9192, 128, 128, 3) dtype=uint8\n",
      "[Dataset] index_train shape=(4596,) dtype=int64\n",
      "[Dataset] index_valid shape=(4596,) dtype=int64\n",
      "[Dataset] labels shape=(9192,) dtype=float64\n",
      "[Dataset] types shape=(9192,) dtype=int32\n"
     ]
    }
   ],
   "source": [
    "def _print_hdf5(name, obj):\n",
    "    indent = \"  \" * name.count(\"/\")\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(f\"{indent}[Dataset] {name} shape={obj.shape} dtype={obj.dtype}\")\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        print(f\"{indent}[Group]   {name}\")\n",
    "\n",
    "\n",
    "def view_dataset(dataset_path):\n",
    "    with h5py.File(dataset_path, \"r\") as f:\n",
    "        f.visititems(_print_hdf5)\n",
    "\n",
    "\n",
    "view_dataset(GENERATE_DATASETS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
