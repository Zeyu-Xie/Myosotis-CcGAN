{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17dfc621",
   "metadata": {},
   "source": [
    "# CcGAN Loaded\n",
    "\n",
    "This notebook is used for loading CcGAN and generating images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d1100",
   "metadata": {},
   "source": [
    "## Step 1 - Import and Settings\n",
    "\n",
    "Import others' libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e679105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380a083",
   "metadata": {},
   "source": [
    "Import our own libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dc0e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7071ff",
   "metadata": {},
   "source": [
    "Set hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "300d52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CcGAN_PATH = \"/home/ubuntu/Desktop/Ra/models/CcGAN/ckpt_SAGAN_niters_30000_nDsteps_2_seed_2020_soft_0.11059499831726932_128.44444444444406.pth\"\n",
    "MODEL_EMBED_PATH = \"/home/ubuntu/Desktop/Ra/models/embed/ResNet34_embed_seed_2020.pth\"\n",
    "MODEL_Y2H_PATH = \"/home/ubuntu/Desktop/Ra/models/embed/ResNet34_y2h_seed_2020.pth\"\n",
    "IMAGE_DIR = \"/home/ubuntu/Desktop/Ra/images/Ra_128_CcGAN_generate\"\n",
    "DIM_GAN = 128\n",
    "NET_EMBED = \"ResNet34_embed\"\n",
    "DIM_EMBED = 128\n",
    "IMG_SIZE = 128\n",
    "MIN_LABEL = 1.5\n",
    "MAX_LABEL = 4.9\n",
    "SEED = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf3110",
   "metadata": {},
   "source": [
    "Settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a97912ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dir\n",
    "if not os.path.exists(IMAGE_DIR):\n",
    "    os.makedirs(IMAGE_DIR)\n",
    "\n",
    "# Set random seed\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e2965",
   "metadata": {},
   "source": [
    "## Step 2 - Load Pretrained Embedding Models\n",
    "\n",
    "In this step we load `net_embed` and `net_y2h` models to CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b535f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): model_y2h(\n",
       "    (main): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (7): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (10): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (13): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if NET_EMBED == \"ResNet18_embed\":\n",
    "    net_embed = ResNet18_embed(dim_embed=DIM_EMBED)\n",
    "elif NET_EMBED == \"ResNet34_embed\":\n",
    "    net_embed = ResNet34_embed(dim_embed=DIM_EMBED)\n",
    "elif NET_EMBED == \"ResNet50_embed\":\n",
    "    net_embed = ResNet50_embed(dim_embed=DIM_EMBED)\n",
    "net_embed = net_embed.cuda()\n",
    "net_embed = nn.DataParallel(net_embed)\n",
    "\n",
    "net_y2h = model_y2h(dim_embed=DIM_EMBED)\n",
    "net_y2h = net_y2h.cuda()\n",
    "net_y2h = nn.DataParallel(net_y2h)\n",
    "\n",
    "## (1). Load net_embed first: x2h+h2y\n",
    "checkpoint = torch.load(MODEL_EMBED_PATH)\n",
    "net_embed.load_state_dict(checkpoint['net_state_dict'])\n",
    "\n",
    "## (2). Load y2h\n",
    "checkpoint = torch.load(MODEL_Y2H_PATH)\n",
    "net_y2h.load_state_dict(checkpoint['net_state_dict'])\n",
    "\n",
    "net_embed.eval()\n",
    "net_h2y = net_embed.module.h2y\n",
    "net_y2h.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d59c7",
   "metadata": {},
   "source": [
    "## Step 3 - Load CcGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b022ac8",
   "metadata": {},
   "source": [
    "This step loads `netG` from `.pth` file, and switch it to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe4284b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CcGAN_SAGAN_Generator(\n",
       "    (snlinear0): Linear(in_features=128, out_features=16384, bias=True)\n",
       "    (block1): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=1024, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=1024, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block2): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=1024, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=1024, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block3): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=256, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=256, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (self_attn): Self_Attn(\n",
       "      (snconv1x1_theta): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (snconv1x1_phi): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (snconv1x1_g): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (snconv1x1_attn): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (block4): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=256, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=256, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block5): GenBlock(\n",
       "      (cond_bn1): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (snconv2d1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cond_bn2): ConditionalBatchNorm2d(\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=False, track_running_stats=True)\n",
       "        (embed_gamma): Linear(in_features=128, out_features=64, bias=False)\n",
       "        (embed_beta): Linear(in_features=128, out_features=64, bias=False)\n",
       "      )\n",
       "      (snconv2d2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (snconv2d0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.0001, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (snconv2d1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(MODEL_CcGAN_PATH)\n",
    "netG = CcGAN_SAGAN_Generator(dim_z=DIM_GAN, dim_embed=DIM_EMBED).cuda()\n",
    "netG = nn.DataParallel(netG)\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc475dd0",
   "metadata": {},
   "source": [
    "## Step 4 - Generate Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca6825",
   "metadata": {},
   "source": [
    "We need to write `labels_to_generate` â€” a `numpy.ndarray` of all the labels (raw) with which we want to generate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32948a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 20 images and saved to /home/ubuntu/Desktop/Ra/images/Ra_128_CcGAN_generate\n"
     ]
    }
   ],
   "source": [
    "# Labels to generate\n",
    "labels_to_generate_raw = np.linspace(MIN_LABEL, MAX_LABEL, num=20).astype(float)\n",
    "\n",
    "# Calculate\n",
    "labels_to_generate = (labels_to_generate_raw - MIN_LABEL) / (MAX_LABEL - MIN_LABEL)\n",
    "z = torch.randn(labels_to_generate.shape[0], IMG_SIZE, dtype=torch.float).cuda()\n",
    "y = torch.from_numpy(labels_to_generate).type(torch.float).reshape(-1,1).cuda()\n",
    "\n",
    "# Generate and save fake images\n",
    "batch_fake_images = netG(z, net_y2h(y))\n",
    "batch_fake_images = batch_fake_images.detach().cpu()\n",
    "for i in range(batch_fake_images.shape[0]):\n",
    "    fake_image = batch_fake_images[i].unsqueeze(0)\n",
    "    save_image(fake_image.data, os.path.join(IMAGE_DIR, f\"{i+1}_{labels_to_generate_raw[i]:.3f}.png\"), nrow=1, normalize=True)\n",
    "print(f\"Generated {len(batch_fake_images)} images and saved to {IMAGE_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
