{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b032790",
   "metadata": {},
   "source": [
    "This notebook aims at processing the original Ra dataset to a more specific one.\n",
    "\n",
    "## Step 1 - Preparations\n",
    "\n",
    "First we need to import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef9aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd2552d",
   "metadata": {},
   "source": [
    "Then we define function `view_dataset` to view the shape of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5718d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_hdf5(name, obj):\n",
    "    indent = \"  \" * name.count(\"/\")\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(f\"{indent}[Dataset] {name} shape={obj.shape} dtype={obj.dtype}\")\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        print(f\"{indent}[Group]   {name}\")\n",
    "\n",
    "def view_dataset(dataset_path):\n",
    "    with h5py.File(dataset_path, \"r\") as f:\n",
    "        f.visititems(_print_hdf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d54f5d",
   "metadata": {},
   "source": [
    "## Step 2 - Load and visualize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b467129",
   "metadata": {},
   "source": [
    "Set `dataset_path` and `new_dataset_path` as the paths of the original and new dataset.\n",
    "\n",
    "Display the structure of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f96baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] images shape=(9192, 128, 128, 3) dtype=uint8\n",
      "[Dataset] index_train shape=(0,) dtype=float64\n",
      "[Dataset] index_valid shape=(0,) dtype=float64\n",
      "[Dataset] labels shape=(9192,) dtype=float64\n",
      "[Dataset] types shape=(9192,) dtype=int32\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "dataset_path = \"/home/ubuntu/Desktop/Ra/datasets/Ra_128.h5\"\n",
    "new_dataset_path = \"/home/ubuntu/Desktop/Ra/datasets/Ra_128_indexed.h5\"\n",
    "\n",
    "# Path\n",
    "if not os.path.exists(os.path.dirname(new_dataset_path)):\n",
    "    os.makedirs(os.path.dirname(new_dataset_path), exist_ok=True)\n",
    "\n",
    "# View the original dataset\n",
    "view_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c213c",
   "metadata": {},
   "source": [
    "From the above output we can see some `numpy` arrays are inside the dataset, including the important ones:\n",
    "\n",
    "1. `images`: includes all the images data\n",
    "2. `labels`: include all the labels regarding the images\n",
    "3. `types`: include all the types regarding the images\n",
    "\n",
    "We have to read and store these three `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c30e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(dataset_path, \"r\") as f:\n",
    "    images = f[\"images\"][:]\n",
    "    labels = f[\"labels\"][:]\n",
    "    types = f[\"types\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f733e40",
   "metadata": {},
   "source": [
    "## Step 3 - Process the data\n",
    "\n",
    "We process the datasets according to our requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eda8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes here\n",
    "N = images.shape[0]\n",
    "index_train = list(range(0, N, 2))\n",
    "index_valid = list(range(1, N, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4d787",
   "metadata": {},
   "source": [
    "## Step 4 - Construct and output the new dataset\n",
    "\n",
    "Now that we have everything for constructing the new dataset, we come to the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9a6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(new_dataset_path, \"w\") as f:\n",
    "    f.create_dataset(\"images\", data=images)\n",
    "    f.create_dataset(\"labels\", data=labels)\n",
    "    f.create_dataset(\"types\", data=types)\n",
    "    f.create_dataset(\"index_train\", data=index_train)\n",
    "    f.create_dataset(\"index_valid\", data=index_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09911ade",
   "metadata": {},
   "source": [
    "We can also view the structure of the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc4ee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] images shape=(9192, 128, 128, 3) dtype=uint8\n",
      "[Dataset] index_train shape=(4596,) dtype=int64\n",
      "[Dataset] index_valid shape=(4596,) dtype=int64\n",
      "[Dataset] labels shape=(9192,) dtype=float64\n",
      "[Dataset] types shape=(9192,) dtype=int32\n"
     ]
    }
   ],
   "source": [
    "view_dataset(new_dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
