{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17dfc621",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d1100",
   "metadata": {},
   "source": [
    "## Step 1 - Import libraries and Load Arguments\n",
    "\n",
    "First we import others' libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e679105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib as mpl\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.utils import save_image\n",
    "import timeit\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380a083",
   "metadata": {},
   "source": [
    "Before we import our own libraries, we should use function `parse_opts_from_preset` from our own library `opts`. This is for getting all the arguments needed in this notebook.\n",
    "\n",
    "(We can also use `parse_opts` function to get the arguments manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75936336",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import my stuffs ###\n",
    "from opts import parse_opts_from_preset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1045af",
   "metadata": {},
   "source": [
    "Here we decide which GAN model to train, possible options:\n",
    "\n",
    "1. `cGAN`\n",
    "2. `cGAN_concat`\n",
    "3. `CcGAN`\n",
    "\n",
    "After loading the arguments, we'd like to print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92eb6b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name                value             type\n",
      "0             root_path  /home/ubuntu/Des...    <class 'str'>\n",
      "1             data_path  /home/ubuntu/Des...    <class 'str'>\n",
      "2        eval_ckpt_path  /home/ubuntu/Des...    <class 'str'>\n",
      "3                  seed                   42    <class 'int'>\n",
      "4           num_workers                    0    <class 'int'>\n",
      "5            data_split                train    <class 'str'>\n",
      "6             min_label                  1.5  <class 'float'>\n",
      "7             max_label                  4.9  <class 'float'>\n",
      "8          num_channels                    3    <class 'int'>\n",
      "9              img_size                  128    <class 'int'>\n",
      "10  max_num_img_per_...                   25    <class 'int'>\n",
      "11  max_num_img_per_...                    0    <class 'int'>\n",
      "12       show_real_imgs                False   <class 'bool'>\n",
      "13  visualize_fake_i...                 True   <class 'bool'>\n",
      "14                  GAN                CcGAN    <class 'str'>\n",
      "15             GAN_arch                SAGAN    <class 'str'>\n",
      "16            net_embed       ResNet34_embed    <class 'str'>\n",
      "17      epoch_cnn_embed                  200    <class 'int'>\n",
      "18  resumeepoch_cnn_...                    0    <class 'int'>\n",
      "19        epoch_net_y2h                  500    <class 'int'>\n",
      "20            dim_embed                  128    <class 'int'>\n",
      "21     batch_size_embed                  256    <class 'int'>\n",
      "22        loss_type_gan                hinge    <class 'str'>\n",
      "23           niters_gan                30000    <class 'int'>\n",
      "24    resume_niters_gan                    0    <class 'int'>\n",
      "25     save_niters_freq                 5000    <class 'int'>\n",
      "26             lr_g_gan               0.0001  <class 'float'>\n",
      "27             lr_d_gan               0.0001  <class 'float'>\n",
      "28              dim_gan                  128    <class 'int'>\n",
      "29      batch_size_disc                   64    <class 'int'>\n",
      "30      batch_size_gene                   64    <class 'int'>\n",
      "31          num_D_steps                    2    <class 'int'>\n",
      "32     cGAN_num_classes                   20    <class 'int'>\n",
      "33       visualize_freq                 1000    <class 'int'>\n",
      "34         kernel_sigma                 -1.0  <class 'float'>\n",
      "35       threshold_type                 soft    <class 'str'>\n",
      "36                kappa                 -2.0  <class 'float'>\n",
      "37  nonzero_soft_wei...                0.001  <class 'float'>\n",
      "38      gan_DiffAugment                 True   <class 'bool'>\n",
      "39  gan_DiffAugment_...  color,translatio...    <class 'str'>\n",
      "40            eval_mode                    2    <class 'int'>\n",
      "41      num_eval_labels                   -1    <class 'int'>\n",
      "42      samp_batch_size                 1000    <class 'int'>\n",
      "43      nfake_per_label                  200    <class 'int'>\n",
      "44      nreal_per_label                   -1    <class 'int'>\n",
      "45             comp_FID                 True   <class 'bool'>\n",
      "46        epoch_FID_CNN                  200    <class 'int'>\n",
      "47           FID_radius                  0.0  <class 'float'>\n",
      "48      FID_num_centers                   -1    <class 'int'>\n",
      "49   dump_fake_for_NIQE                 True   <class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "# Load arguments from a preset configuration\n",
    "args = parse_opts_from_preset(\"CcGAN\")\n",
    "\n",
    "# Print the arguments in a DataFrame format\n",
    "args_df = pd.DataFrame([{'name': key, 'value': value, 'type': type(value)} for key, value in vars(args).items()])\n",
    "pd.set_option('display.max_colwidth', 20)\n",
    "print(args_df)\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a654f87",
   "metadata": {},
   "source": [
    "We should also add the `args.root_path` to the environment, so as to import our own libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc0e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = args.root_path\n",
    "os.chdir(wd)\n",
    "from utils import *\n",
    "from models import *\n",
    "from train_cgan import train_cgan, sample_cgan_given_labels\n",
    "from train_cgan_concat import train_cgan_concat, sample_cgan_concat_given_labels\n",
    "from train_ccgan import train_ccgan, sample_ccgan_given_labels\n",
    "from train_net_for_label_embed import train_net_embed, train_net_y2h\n",
    "from eval_metrics import cal_FID, cal_labelscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d911c91",
   "metadata": {},
   "source": [
    "## Step 2 - Settings\n",
    "\n",
    "In this part we would like to make configurations to the following areas:\n",
    "\n",
    "1. Random seeds\n",
    "2. Output folders\n",
    "3. Hyperparameters for embedding models (`x2y` and `y2h`)\n",
    "\n",
    "We may also add other settings items here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bc8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "'''                                   Settings                                      '''\n",
    "#######################################################################################\n",
    "#-------------------------------\n",
    "# seeds\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "#-------------------------------\n",
    "# output folders\n",
    "path_to_output = os.path.join(wd, \"output/output_{}_arch_{}\".format(args.GAN, args.GAN_arch))\n",
    "os.makedirs(path_to_output, exist_ok=True)\n",
    "save_models_folder = os.path.join(path_to_output, 'saved_models') # The folder to save trained models\n",
    "os.makedirs(save_models_folder, exist_ok=True)\n",
    "save_images_folder = os.path.join(path_to_output, 'saved_images') # The folder to save generated images\n",
    "os.makedirs(save_images_folder, exist_ok=True)\n",
    "path_to_embed_models = os.path.join(wd, 'output/embed_models') # The folder to save trained embedding models\n",
    "os.makedirs(path_to_embed_models, exist_ok=True)\n",
    "\n",
    "#-------------------------------\n",
    "# Embedding\n",
    "base_lr_x2y = 0.01\n",
    "base_lr_y2h = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e5f62",
   "metadata": {},
   "source": [
    "## Step 3 - Load and Process Data\n",
    "\n",
    "In this part we load and process the data.\n",
    "\n",
    "First we define some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fd4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_hdf5(name, obj):\n",
    "    indent = \"  \" * name.count(\"/\")\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(f\"{indent}[Dataset] {name} shape={obj.shape} dtype={obj.dtype}\")\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        print(f\"{indent}[Group]   {name}\")\n",
    "\n",
    "def view_dataset(dataset_path):\n",
    "    with h5py.File(dataset_path, \"r\") as f:\n",
    "        f.visititems(_print_hdf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801cd5a",
   "metadata": {},
   "source": [
    "In the next code block we will get the following `numpy.ndarray`: \n",
    "\n",
    "1. `labels_all`: all the original labels\n",
    "2. `images_all`: all the original images, shape `(N, 3, H, W)`\n",
    "3. `index_train`: indexes for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0890e8c",
   "metadata": {},
   "source": [
    "### Step 3.1 - Load data from the `.h5` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f564e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] images shape=(300, 128, 128, 3) dtype=uint8\n",
      "[Dataset] index_train shape=(150,) dtype=int64\n",
      "[Dataset] index_valid shape=(150,) dtype=int64\n",
      "[Dataset] labels shape=(300,) dtype=float64\n",
      "[Dataset] types shape=(300,) dtype=int32\n",
      "\n",
      "`images_all` shape: (300, 3, 128, 128), dtype: uint8\n",
      "`labels_all` shape: (300,), dtype: float64\n",
      "`index_train` shape: (150,), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "'''                                    Data loader                                 '''\n",
    "#######################################################################################\n",
    "# Data path\n",
    "data_filename = args.data_path + '/Ra_128_indexed_binned.h5'\n",
    "\n",
    "# View dataset structure\n",
    "view_dataset(data_filename)\n",
    "print(\"\")\n",
    "\n",
    "# Load data from h5 file\n",
    "hf = h5py.File(data_filename, 'r')\n",
    "labels_all = hf['labels'][:]\n",
    "images_all = hf['images'][:]\n",
    "index_train = hf['index_train'][:]\n",
    "hf.close()\n",
    "\n",
    "# Change the data type and shape to fit the model\n",
    "labels_all = labels_all.astype(float)\n",
    "images_all = images_all.transpose(0, 3, 1, 2)\n",
    "\n",
    "print(f\"`images_all` shape: {images_all.shape}, dtype: {images_all.dtype}\")\n",
    "print(f\"`labels_all` shape: {labels_all.shape}, dtype: {labels_all.dtype}\")\n",
    "print(f\"`index_train` shape: {index_train.shape}, dtype: {index_train.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cea6c9",
   "metadata": {},
   "source": [
    "### Step 3.2 - Split the training dataset\n",
    "\n",
    "We split the data. Rule:\n",
    "\n",
    "- If `args.data_split` is `train`, use `index_train` as the set of training indexes.\n",
    "- Otherwise, use all data as the training set.\n",
    "\n",
    "After the next block we will get:\n",
    "\n",
    "1. `images_train`: the training set images (subset of `images_all`)\n",
    "2. `labels_train_raw`: the training set labels (subset of `labels_all`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdbf0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: train\n",
      "\n",
      "`images_train` shape: (150, 3, 128, 128), dtype: uint8\n",
      "`labels_train_raw` shape: (150,), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# data split\n",
    "print(f\"Data split: {args.data_split}\")\n",
    "print(\"\")\n",
    "if args.data_split == \"train\":\n",
    "    images_train = images_all[index_train]\n",
    "    labels_train_raw = labels_all[index_train]\n",
    "else:\n",
    "    images_train = copy.deepcopy(images_all)\n",
    "    labels_train_raw = copy.deepcopy(labels_all)\n",
    "\n",
    "# Print the data split result\n",
    "print(f\"`images_train` shape: {images_train.shape}, dtype: {images_train.dtype}\")\n",
    "print(f\"`labels_train_raw` shape: {labels_train_raw.shape}, dtype: {labels_train_raw.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac452e",
   "metadata": {},
   "source": [
    "### Step 3.3 - Label range limitation\n",
    "\n",
    "We only take images with label in $\\left(q_1, q_2\\right)$, where $q_1 = \\text{min label}$ and $q_2 = \\text{max label}$.\n",
    "\n",
    "In the following block we set limitation on training data. And if `args.visualize_fake_images` is `True` or `args.comp_FID` is `True`, we will also set limitation on all data.\n",
    "\n",
    "In this part we updated `images_train` and `labels_train_raw` (training data), as well as `images_all` and `labels_all` (all data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abb4f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`images_train` shape: (150, 3, 128, 128), dtype: uint8\n",
      "`labels_train_raw` shape: (150,), dtype: float64\n",
      "\n",
      "`images_all` shape: (300, 3, 128, 128), dtype: uint8\n",
      "`labels_all` shape: (300,), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Limitation on training data\n",
    "q1 = args.min_label\n",
    "q2 = args.max_label\n",
    "indx = np.where((labels_train_raw>q1)*(labels_train_raw<q2)==True)[0]\n",
    "labels_train_raw = labels_train_raw[indx]\n",
    "images_train = images_train[indx]\n",
    "assert len(labels_train_raw)==len(images_train)\n",
    "print(f\"`images_train` shape: {images_train.shape}, dtype: {images_train.dtype}\")\n",
    "print(f\"`labels_train_raw` shape: {labels_train_raw.shape}, dtype: {labels_train_raw.dtype}\")\n",
    "print(\"\")\n",
    "\n",
    "# Limitation on all data\n",
    "if args.visualize_fake_images or args.comp_FID:\n",
    "    indx = np.where((labels_all>q1)*(labels_all<q2)==True)[0]\n",
    "    labels_all = labels_all[indx]\n",
    "    images_all = images_all[indx]\n",
    "    assert len(labels_all)==len(images_all)\n",
    "    print(f\"`images_all` shape: {images_all.shape}, dtype: {images_all.dtype}\")\n",
    "    print(f\"`labels_all` shape: {labels_all.shape}, dtype: {labels_all.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4571001",
   "metadata": {},
   "source": [
    "If `args.show_real_images` is set `True`, then we will save some real images locally from `images_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df836e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some real images\n",
    "if args.show_real_imgs:\n",
    "    unique_labels_show = np.array(sorted(list(set(labels_all))))\n",
    "    indx_show = np.arange(0, len(unique_labels_show), len(unique_labels_show)//9)\n",
    "    unique_labels_show = unique_labels_show[indx_show]\n",
    "    nrow = len(unique_labels_show); ncol = 1\n",
    "    sel_labels_indx = []\n",
    "    for i in range(nrow):\n",
    "        curr_label = unique_labels_show[i]\n",
    "        indx_curr_label = np.where(labels_all==curr_label)[0]\n",
    "        np.random.shuffle(indx_curr_label)\n",
    "        indx_curr_label = indx_curr_label[0:ncol]\n",
    "        sel_labels_indx.extend(list(indx_curr_label))\n",
    "    sel_labels_indx = np.array(sel_labels_indx)\n",
    "    images_show = images_all[sel_labels_indx]\n",
    "    print(images_show.mean())\n",
    "    images_show = (images_show/255.0-0.5)/0.5\n",
    "    images_show = torch.from_numpy(images_show)\n",
    "    save_image(images_show.data, save_images_folder +'/real_images_grid_{}x{}.png'.format(nrow, ncol), nrow=ncol, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77b06e",
   "metadata": {},
   "source": [
    "### Step 3.4 - Image number limitation\n",
    "\n",
    "For each label value, we allow at most `args.max_num_img_per_label` images occur in the training set. This step randomly selects the images and labels and update `images_train` and `labels_train_raw`.\n",
    "\n",
    "This step may only have influences on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641157f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set has 150 images; For each angle, take no more than 25 images>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:00<00:00, 120123.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 images left and there are 132 unique labels\n",
      "\n",
      "`images_train` shape: (150, 3, 128, 128), dtype: uint8\n",
      "`labels_train_raw` shape: (150,), dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each angle, take no more than args.max_num_img_per_label images\n",
    "image_num_threshold = args.max_num_img_per_label\n",
    "print(\"Original set has {} images; For each angle, take no more than {} images>>>\".format(len(images_train), image_num_threshold))\n",
    "unique_labels_tmp = np.sort(np.array(list(set(labels_train_raw))))\n",
    "for i in tqdm(range(len(unique_labels_tmp))):\n",
    "    indx_i = np.where(labels_train_raw == unique_labels_tmp[i])[0]\n",
    "    if len(indx_i)>image_num_threshold:\n",
    "        np.random.shuffle(indx_i)\n",
    "        indx_i = indx_i[0:image_num_threshold]\n",
    "    if i == 0:\n",
    "        sel_indx = indx_i\n",
    "    else:\n",
    "        sel_indx = np.concatenate((sel_indx, indx_i))\n",
    "images_train = images_train[sel_indx]\n",
    "labels_train_raw = labels_train_raw[sel_indx]\n",
    "print(\"{} images left and there are {} unique labels\".format(len(images_train), len(set(labels_train_raw))))\n",
    "print(\"\")\n",
    "print(f\"`images_train` shape: {images_train.shape}, dtype: {images_train.dtype}\")\n",
    "print(f\"`labels_train_raw` shape: {labels_train_raw.shape}, dtype: {labels_train_raw.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fe402",
   "metadata": {},
   "source": [
    "### Step 3.5 - Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "981f7412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of unnormalized labels: (1.566,4.821)\n",
      "Preset `min_label`: 1.5, `max_label`: 4.9\n"
     ]
    }
   ],
   "source": [
    "# Print the range of unnormalized `labels_train_raw`\n",
    "print(\"Range of unnormalized labels: ({},{})\".format(np.min(labels_train_raw), np.max(labels_train_raw)))\n",
    "\n",
    "# Print the preset `args.min_label` and `args.max_label`\n",
    "print(\"Preset `min_label`: {}, `max_label`: {}\".format(args.min_label, args.max_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f0a67",
   "metadata": {},
   "source": [
    "#### Case 1 - `cGAN`\n",
    "\n",
    "In this case the task is treated as classification, and the labels are converted to class labels.\n",
    "\n",
    "The normalization result is in `labels_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d20a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training cGAN.\n"
     ]
    }
   ],
   "source": [
    "if args.GAN != \"cGAN\":\n",
    "    print(\"Not training cGAN.\")\n",
    "\n",
    "else: #treated as classification; convert angles to class labels\n",
    "    unique_labels = np.sort(np.array(list(set(labels_train_raw))))\n",
    "    num_unique_labels = len(unique_labels)\n",
    "    print(\"{} unique labels are split into {} classes\".format(num_unique_labels, args.cGAN_num_classes))\n",
    "\n",
    "    ## convert steering angles to class labels and vice versa\n",
    "    ### step 1: prepare two dictionaries\n",
    "    label2class = dict()\n",
    "    class2label = dict()\n",
    "    num_labels_per_class = num_unique_labels//args.cGAN_num_classes\n",
    "    class_cutoff_points = [unique_labels[0]] #the cutoff points on [min_label, max_label] to determine classes\n",
    "    curr_class = 0\n",
    "    for i in range(num_unique_labels):\n",
    "        label2class[unique_labels[i]]=curr_class\n",
    "        if (i+1)%num_labels_per_class==0 and (curr_class+1)!=args.cGAN_num_classes:\n",
    "            curr_class += 1\n",
    "            class_cutoff_points.append(unique_labels[i+1])\n",
    "    class_cutoff_points.append(unique_labels[-1])\n",
    "    assert len(class_cutoff_points)-1 == args.cGAN_num_classes\n",
    "\n",
    "    for i in range(args.cGAN_num_classes):\n",
    "        class2label[i] = (class_cutoff_points[i]+class_cutoff_points[i+1])/2\n",
    "\n",
    "    ### step 2: convert angles to class labels\n",
    "    labels_new = -1*np.ones(len(labels_train_raw))\n",
    "    for i in range(len(labels_train_raw)):\n",
    "        labels_new[i] = label2class[labels_train_raw[i]]\n",
    "    assert np.sum(labels_new<0)==0\n",
    "    labels_train = labels_new\n",
    "    del labels_new; gc.collect()\n",
    "    unique_labels = np.sort(np.array(list(set(labels_train)))).astype(int)\n",
    "    assert len(unique_labels) == args.cGAN_num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f04b6",
   "metadata": {},
   "source": [
    "#### Case 2 - `CcGAN`\n",
    "\n",
    "In this case we not only normalize the `labels_train`, but calculate $\\sigma$ and $\\kappa$ value of the dataset (if `args.kernel_sigma` or `args.kappa` is negative).\n",
    "\n",
    "The `labels_train_raw` array is divided by `args.max_label`, and we store the normalized training data labels to `labels_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490b3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preset `min_label`: 1.5, `max_label`: 4.9\n",
      "Range of `labels_train_row`: (1.566,4.821)\n",
      "Range of `labels_train`: (0.019411764705882368,0.9767647058823528)\n",
      "\n",
      "Use rule-of-thumb formula to compute kernel_sigma.\n",
      "The std of 150 labels is 0.28421557456592034 so the kernel sigma is 0.11059499831726932\n"
     ]
    }
   ],
   "source": [
    "if args.GAN != \"CcGAN\":\n",
    "    print(\"Not training CcGAN.\")\n",
    "\n",
    "else:\n",
    "    # Normalize labels\n",
    "    labels_train = (labels_train_raw - args.min_label) / (args.max_label - args.min_label)    \n",
    "    print(\"Preset `min_label`: {}, `max_label`: {}\".format(args.min_label, args.max_label))\n",
    "    print(\"Range of `labels_train_row`: ({},{})\".format(np.min(labels_train_raw), np.max(labels_train_raw)))\n",
    "    print(\"Range of `labels_train`: ({},{})\".format(np.min(labels_train), np.max(labels_train)))\n",
    "\n",
    "    unique_labels_norm = np.sort(np.array(list(set(labels_train))))\n",
    "\n",
    "    # Set `kernel_sigma`\n",
    "    if args.kernel_sigma<0:\n",
    "        std_label = np.std(labels_train)\n",
    "        args.kernel_sigma = 1.06*std_label*(len(labels_train))**(-1/5)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Use rule-of-thumb formula to compute kernel_sigma.\")\n",
    "        print(\"The std of {} labels is {} so the kernel sigma is {}\".format(len(labels_train), std_label, args.kernel_sigma))\n",
    "\n",
    "    # Set `kappa`\n",
    "    if args.kappa<0:\n",
    "        n_unique = len(unique_labels_norm)\n",
    "\n",
    "        diff_list = []\n",
    "        for i in range(1,n_unique):\n",
    "            diff_list.append(unique_labels_norm[i] - unique_labels_norm[i-1])\n",
    "        kappa_base = np.abs(args.kappa)*np.max(np.array(diff_list))\n",
    "\n",
    "        if args.threshold_type==\"hard\":\n",
    "            args.kappa = kappa_base\n",
    "        else:\n",
    "            args.kappa = 1/kappa_base**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306f2a7",
   "metadata": {},
   "source": [
    "#### Case 3 - `cGAN-concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c0d2995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training cGAN-concat.\n"
     ]
    }
   ],
   "source": [
    "if args.GAN != \"cGAN-concat\":\n",
    "    print(\"Not training cGAN-concat.\")\n",
    "\n",
    "else:\n",
    "    labels_train = (labels_train_raw - args.min_label) / (args.max_label - args.min_label)\n",
    "    print(\"Range of normalized labels: ({},{})\".format(np.min(labels_train), np.max(labels_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa168974",
   "metadata": {},
   "source": [
    "#### Case 4 - None of the above\n",
    "\n",
    "Then we raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906b899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.GAN not in [\"cGAN\", \"CcGAN\", \"cGAN-concat\"]:\n",
    "    raise ValueError('Not supported')\n",
    "\n",
    "## end if args.GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e2965",
   "metadata": {},
   "source": [
    "## Step 4 - Pre-trained CNN and GAN for Label Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2bd86",
   "metadata": {},
   "source": [
    "We only need this step if `args.GAN` is `CcGAN`.\n",
    "\n",
    "The pretrained embedding network is a ResNet (defined in `models/ResNet_embed.py`). We can choose it among `ResNet18_embed`, `ResNet34_embed` and `ResNet50_embed`.\n",
    "\n",
    "The images set is `images_train` and the labels set is `labels_train`.\n",
    "\n",
    "In this step we get `net_embed` (i.e. `x2h + h2y`) and `net_y2h`, both on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b535f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /home/ubuntu/Desktop/Myosotis-CcGAN/codes/main/output/embed_models/ckpt_ResNet34_embed_epoch_200_seed_42.pth\n",
      "\n",
      " /home/ubuntu/Desktop/Myosotis-CcGAN/codes/main/output/embed_models/ckpt_net_y2h_epoch_500_seed_42.pth\n",
      "\n",
      " Start training CNN for label embedding >>>\n",
      "Train net_x2y for embedding: [epoch 1/200] train_loss:0.229074 Time:0.5789\n",
      "Train net_x2y for embedding: [epoch 2/200] train_loss:0.194665 Time:0.7700\n",
      "Train net_x2y for embedding: [epoch 3/200] train_loss:0.145999 Time:0.9449\n",
      "Train net_x2y for embedding: [epoch 4/200] train_loss:0.109129 Time:1.1008\n",
      "Train net_x2y for embedding: [epoch 5/200] train_loss:0.310141 Time:1.2543\n",
      "Train net_x2y for embedding: [epoch 6/200] train_loss:0.073868 Time:1.4084\n",
      "Train net_x2y for embedding: [epoch 7/200] train_loss:0.063098 Time:1.5629\n",
      "Train net_x2y for embedding: [epoch 8/200] train_loss:0.066939 Time:1.7171\n",
      "Train net_x2y for embedding: [epoch 9/200] train_loss:0.039355 Time:1.8711\n",
      "Train net_x2y for embedding: [epoch 10/200] train_loss:0.030998 Time:2.0251\n",
      "Train net_x2y for embedding: [epoch 11/200] train_loss:0.020506 Time:2.1786\n",
      "Train net_x2y for embedding: [epoch 12/200] train_loss:0.016997 Time:2.3326\n",
      "Train net_x2y for embedding: [epoch 13/200] train_loss:0.014063 Time:2.4866\n",
      "Train net_x2y for embedding: [epoch 14/200] train_loss:0.012643 Time:2.6409\n",
      "Train net_x2y for embedding: [epoch 15/200] train_loss:0.011281 Time:2.7950\n",
      "Train net_x2y for embedding: [epoch 16/200] train_loss:0.010226 Time:2.9492\n",
      "Train net_x2y for embedding: [epoch 17/200] train_loss:0.009443 Time:3.1035\n",
      "Train net_x2y for embedding: [epoch 18/200] train_loss:0.009008 Time:3.2580\n",
      "Train net_x2y for embedding: [epoch 19/200] train_loss:0.008570 Time:3.4120\n",
      "Train net_x2y for embedding: [epoch 20/200] train_loss:0.008216 Time:3.5664\n",
      "Train net_x2y for embedding: [epoch 21/200] train_loss:0.008022 Time:3.7203\n",
      "Train net_x2y for embedding: [epoch 22/200] train_loss:0.007992 Time:3.8745\n",
      "Train net_x2y for embedding: [epoch 23/200] train_loss:0.007970 Time:4.0297\n",
      "Train net_x2y for embedding: [epoch 24/200] train_loss:0.007884 Time:4.1844\n",
      "Train net_x2y for embedding: [epoch 25/200] train_loss:0.007824 Time:4.3384\n",
      "Train net_x2y for embedding: [epoch 26/200] train_loss:0.007757 Time:4.4930\n",
      "Train net_x2y for embedding: [epoch 27/200] train_loss:0.007762 Time:4.6475\n",
      "Train net_x2y for embedding: [epoch 28/200] train_loss:0.007746 Time:4.8022\n",
      "Train net_x2y for embedding: [epoch 29/200] train_loss:0.007737 Time:4.9571\n",
      "Train net_x2y for embedding: [epoch 30/200] train_loss:0.007698 Time:5.1122\n",
      "Train net_x2y for embedding: [epoch 31/200] train_loss:0.007658 Time:5.2663\n",
      "Train net_x2y for embedding: [epoch 32/200] train_loss:0.007650 Time:5.4224\n",
      "Train net_x2y for embedding: [epoch 33/200] train_loss:0.007650 Time:5.5769\n",
      "Train net_x2y for embedding: [epoch 34/200] train_loss:0.007637 Time:5.7315\n",
      "Train net_x2y for embedding: [epoch 35/200] train_loss:0.007622 Time:5.8855\n",
      "Train net_x2y for embedding: [epoch 36/200] train_loss:0.007611 Time:6.0402\n",
      "Train net_x2y for embedding: [epoch 37/200] train_loss:0.007602 Time:6.1943\n",
      "Train net_x2y for embedding: [epoch 38/200] train_loss:0.007593 Time:6.3492\n",
      "Train net_x2y for embedding: [epoch 39/200] train_loss:0.007607 Time:6.5030\n",
      "Train net_x2y for embedding: [epoch 40/200] train_loss:0.007588 Time:6.6575\n",
      "Train net_x2y for embedding: [epoch 41/200] train_loss:0.007588 Time:6.8117\n",
      "Train net_x2y for embedding: [epoch 42/200] train_loss:0.007584 Time:6.9666\n",
      "Train net_x2y for embedding: [epoch 43/200] train_loss:0.007579 Time:7.1214\n",
      "Train net_x2y for embedding: [epoch 44/200] train_loss:0.007577 Time:7.2758\n",
      "Train net_x2y for embedding: [epoch 45/200] train_loss:0.007570 Time:7.4301\n",
      "Train net_x2y for embedding: [epoch 46/200] train_loss:0.007566 Time:7.5846\n",
      "Train net_x2y for embedding: [epoch 47/200] train_loss:0.007562 Time:7.7387\n",
      "Train net_x2y for embedding: [epoch 48/200] train_loss:0.006130 Time:7.8930\n",
      "Train net_x2y for embedding: [epoch 49/200] train_loss:0.005153 Time:8.0477\n",
      "Train net_x2y for embedding: [epoch 50/200] train_loss:0.005309 Time:8.2021\n",
      "Train net_x2y for embedding: [epoch 51/200] train_loss:0.005361 Time:8.6081\n",
      "Train net_x2y for embedding: [epoch 52/200] train_loss:0.003946 Time:8.7621\n",
      "Train net_x2y for embedding: [epoch 53/200] train_loss:0.001592 Time:8.9158\n",
      "Train net_x2y for embedding: [epoch 54/200] train_loss:0.003398 Time:9.0699\n",
      "Train net_x2y for embedding: [epoch 55/200] train_loss:0.001430 Time:9.2237\n",
      "Train net_x2y for embedding: [epoch 56/200] train_loss:0.001611 Time:9.3780\n",
      "Train net_x2y for embedding: [epoch 57/200] train_loss:0.002108 Time:9.5326\n",
      "Train net_x2y for embedding: [epoch 58/200] train_loss:0.000725 Time:9.6881\n",
      "Train net_x2y for embedding: [epoch 59/200] train_loss:0.001243 Time:9.8424\n",
      "Train net_x2y for embedding: [epoch 60/200] train_loss:0.001322 Time:9.9972\n",
      "Train net_x2y for embedding: [epoch 61/200] train_loss:0.000394 Time:10.1517\n",
      "Train net_x2y for embedding: [epoch 62/200] train_loss:0.000791 Time:10.3064\n",
      "Train net_x2y for embedding: [epoch 63/200] train_loss:0.000871 Time:10.4606\n",
      "Train net_x2y for embedding: [epoch 64/200] train_loss:0.000381 Time:10.6153\n",
      "Train net_x2y for embedding: [epoch 65/200] train_loss:0.000480 Time:10.7694\n",
      "Train net_x2y for embedding: [epoch 66/200] train_loss:0.000654 Time:10.9239\n",
      "Train net_x2y for embedding: [epoch 67/200] train_loss:0.000307 Time:11.0787\n",
      "Train net_x2y for embedding: [epoch 68/200] train_loss:0.000280 Time:11.2333\n",
      "Train net_x2y for embedding: [epoch 69/200] train_loss:0.000425 Time:11.3875\n",
      "Train net_x2y for embedding: [epoch 70/200] train_loss:0.000274 Time:11.5425\n",
      "Train net_x2y for embedding: [epoch 71/200] train_loss:0.000116 Time:11.6970\n",
      "Train net_x2y for embedding: [epoch 72/200] train_loss:0.000296 Time:11.8516\n",
      "Train net_x2y for embedding: [epoch 73/200] train_loss:0.000205 Time:12.0061\n",
      "Train net_x2y for embedding: [epoch 74/200] train_loss:0.000101 Time:12.1609\n",
      "Train net_x2y for embedding: [epoch 75/200] train_loss:0.000186 Time:12.3154\n",
      "Train net_x2y for embedding: [epoch 76/200] train_loss:0.000172 Time:12.4698\n",
      "Train net_x2y for embedding: [epoch 77/200] train_loss:0.000076 Time:12.6241\n",
      "Train net_x2y for embedding: [epoch 78/200] train_loss:0.000111 Time:12.7787\n",
      "Train net_x2y for embedding: [epoch 79/200] train_loss:0.000121 Time:12.9335\n",
      "Train net_x2y for embedding: [epoch 80/200] train_loss:0.000062 Time:13.0884\n",
      "Train net_x2y for embedding: [epoch 81/200] train_loss:0.000074 Time:13.2431\n",
      "Train net_x2y for embedding: [epoch 82/200] train_loss:0.000072 Time:13.4008\n",
      "Train net_x2y for embedding: [epoch 83/200] train_loss:0.000062 Time:13.5554\n",
      "Train net_x2y for embedding: [epoch 84/200] train_loss:0.000049 Time:13.7102\n",
      "Train net_x2y for embedding: [epoch 85/200] train_loss:0.000036 Time:13.8646\n",
      "Train net_x2y for embedding: [epoch 86/200] train_loss:0.000026 Time:14.0197\n",
      "Train net_x2y for embedding: [epoch 87/200] train_loss:0.000022 Time:14.1747\n",
      "Train net_x2y for embedding: [epoch 88/200] train_loss:0.000020 Time:14.3315\n",
      "Train net_x2y for embedding: [epoch 89/200] train_loss:0.000021 Time:14.4877\n",
      "Train net_x2y for embedding: [epoch 90/200] train_loss:0.000022 Time:14.6449\n",
      "Train net_x2y for embedding: [epoch 91/200] train_loss:0.000022 Time:14.8002\n",
      "Train net_x2y for embedding: [epoch 92/200] train_loss:0.000020 Time:14.9571\n",
      "Train net_x2y for embedding: [epoch 93/200] train_loss:0.000018 Time:15.1144\n",
      "Train net_x2y for embedding: [epoch 94/200] train_loss:0.000015 Time:15.2695\n",
      "Train net_x2y for embedding: [epoch 95/200] train_loss:0.000012 Time:15.4242\n",
      "Train net_x2y for embedding: [epoch 96/200] train_loss:0.000010 Time:15.5791\n",
      "Train net_x2y for embedding: [epoch 97/200] train_loss:0.000008 Time:15.7336\n",
      "Train net_x2y for embedding: [epoch 98/200] train_loss:0.000007 Time:15.8888\n",
      "Train net_x2y for embedding: [epoch 99/200] train_loss:0.000006 Time:16.0437\n",
      "Train net_x2y for embedding: [epoch 100/200] train_loss:0.000006 Time:16.1986\n",
      "Train net_x2y for embedding: [epoch 101/200] train_loss:0.000006 Time:16.5783\n",
      "Train net_x2y for embedding: [epoch 102/200] train_loss:0.000006 Time:16.7321\n",
      "Train net_x2y for embedding: [epoch 103/200] train_loss:0.000006 Time:16.8856\n",
      "Train net_x2y for embedding: [epoch 104/200] train_loss:0.000006 Time:17.0396\n",
      "Train net_x2y for embedding: [epoch 105/200] train_loss:0.000005 Time:17.1931\n",
      "Train net_x2y for embedding: [epoch 106/200] train_loss:0.000004 Time:17.3474\n",
      "Train net_x2y for embedding: [epoch 107/200] train_loss:0.000003 Time:17.5014\n",
      "Train net_x2y for embedding: [epoch 108/200] train_loss:0.000002 Time:17.6557\n",
      "Train net_x2y for embedding: [epoch 109/200] train_loss:0.000002 Time:17.8100\n",
      "Train net_x2y for embedding: [epoch 110/200] train_loss:0.000002 Time:17.9651\n",
      "Train net_x2y for embedding: [epoch 111/200] train_loss:0.000002 Time:18.1190\n",
      "Train net_x2y for embedding: [epoch 112/200] train_loss:0.000002 Time:18.2733\n",
      "Train net_x2y for embedding: [epoch 113/200] train_loss:0.000002 Time:18.4272\n",
      "Train net_x2y for embedding: [epoch 114/200] train_loss:0.000002 Time:18.5816\n",
      "Train net_x2y for embedding: [epoch 115/200] train_loss:0.000002 Time:18.7356\n",
      "Train net_x2y for embedding: [epoch 116/200] train_loss:0.000001 Time:18.8899\n",
      "Train net_x2y for embedding: [epoch 117/200] train_loss:0.000001 Time:19.0442\n",
      "Train net_x2y for embedding: [epoch 118/200] train_loss:0.000001 Time:19.1985\n",
      "Train net_x2y for embedding: [epoch 119/200] train_loss:0.000001 Time:19.3526\n",
      "Train net_x2y for embedding: [epoch 120/200] train_loss:0.000001 Time:19.5069\n",
      "Train net_x2y for embedding: [epoch 121/200] train_loss:0.000001 Time:19.6612\n",
      "Train net_x2y for embedding: [epoch 122/200] train_loss:0.000001 Time:19.8155\n",
      "Train net_x2y for embedding: [epoch 123/200] train_loss:0.000001 Time:19.9698\n",
      "Train net_x2y for embedding: [epoch 124/200] train_loss:0.000001 Time:20.1244\n",
      "Train net_x2y for embedding: [epoch 125/200] train_loss:0.000001 Time:20.2786\n",
      "Train net_x2y for embedding: [epoch 126/200] train_loss:0.000001 Time:20.4332\n",
      "Train net_x2y for embedding: [epoch 127/200] train_loss:0.000000 Time:20.5877\n",
      "Train net_x2y for embedding: [epoch 128/200] train_loss:0.000000 Time:20.7421\n",
      "Train net_x2y for embedding: [epoch 129/200] train_loss:0.000000 Time:20.8961\n",
      "Train net_x2y for embedding: [epoch 130/200] train_loss:0.000000 Time:21.0509\n",
      "Train net_x2y for embedding: [epoch 131/200] train_loss:0.000000 Time:21.2049\n",
      "Train net_x2y for embedding: [epoch 132/200] train_loss:0.000000 Time:21.3595\n",
      "Train net_x2y for embedding: [epoch 133/200] train_loss:0.000000 Time:21.5141\n",
      "Train net_x2y for embedding: [epoch 134/200] train_loss:0.000000 Time:21.6684\n",
      "Train net_x2y for embedding: [epoch 135/200] train_loss:0.000000 Time:21.8226\n",
      "Train net_x2y for embedding: [epoch 136/200] train_loss:0.000000 Time:21.9774\n",
      "Train net_x2y for embedding: [epoch 137/200] train_loss:0.000000 Time:22.1318\n",
      "Train net_x2y for embedding: [epoch 138/200] train_loss:0.000000 Time:22.2862\n",
      "Train net_x2y for embedding: [epoch 139/200] train_loss:0.000000 Time:22.4404\n",
      "Train net_x2y for embedding: [epoch 140/200] train_loss:0.000000 Time:22.5952\n",
      "Train net_x2y for embedding: [epoch 141/200] train_loss:0.000000 Time:22.7495\n",
      "Train net_x2y for embedding: [epoch 142/200] train_loss:0.000000 Time:22.9038\n",
      "Train net_x2y for embedding: [epoch 143/200] train_loss:0.000000 Time:23.0584\n",
      "Train net_x2y for embedding: [epoch 144/200] train_loss:0.000000 Time:23.2129\n",
      "Train net_x2y for embedding: [epoch 145/200] train_loss:0.000000 Time:23.3670\n",
      "Train net_x2y for embedding: [epoch 146/200] train_loss:0.000000 Time:23.5214\n",
      "Train net_x2y for embedding: [epoch 147/200] train_loss:0.000000 Time:23.6756\n",
      "Train net_x2y for embedding: [epoch 148/200] train_loss:0.000000 Time:23.8300\n",
      "Train net_x2y for embedding: [epoch 149/200] train_loss:0.000000 Time:23.9842\n",
      "Train net_x2y for embedding: [epoch 150/200] train_loss:0.000000 Time:24.1388\n",
      "Train net_x2y for embedding: [epoch 151/200] train_loss:0.000000 Time:24.5177\n",
      "Train net_x2y for embedding: [epoch 152/200] train_loss:0.000000 Time:24.6715\n",
      "Train net_x2y for embedding: [epoch 153/200] train_loss:0.000000 Time:24.8248\n",
      "Train net_x2y for embedding: [epoch 154/200] train_loss:0.000000 Time:24.9787\n",
      "Train net_x2y for embedding: [epoch 155/200] train_loss:0.000000 Time:25.1321\n",
      "Train net_x2y for embedding: [epoch 156/200] train_loss:0.000000 Time:25.2862\n",
      "Train net_x2y for embedding: [epoch 157/200] train_loss:0.000000 Time:25.4399\n",
      "Train net_x2y for embedding: [epoch 158/200] train_loss:0.000000 Time:25.5945\n",
      "Train net_x2y for embedding: [epoch 159/200] train_loss:0.000000 Time:25.7486\n",
      "Train net_x2y for embedding: [epoch 160/200] train_loss:0.000000 Time:25.9031\n",
      "Train net_x2y for embedding: [epoch 161/200] train_loss:0.000000 Time:26.0572\n",
      "Train net_x2y for embedding: [epoch 162/200] train_loss:0.000000 Time:26.2114\n",
      "Train net_x2y for embedding: [epoch 163/200] train_loss:0.000000 Time:26.3659\n",
      "Train net_x2y for embedding: [epoch 164/200] train_loss:0.000000 Time:26.5204\n",
      "Train net_x2y for embedding: [epoch 165/200] train_loss:0.000000 Time:26.6744\n",
      "Train net_x2y for embedding: [epoch 166/200] train_loss:0.000000 Time:26.8287\n",
      "Train net_x2y for embedding: [epoch 167/200] train_loss:0.000000 Time:26.9830\n",
      "Train net_x2y for embedding: [epoch 168/200] train_loss:0.000000 Time:27.1375\n",
      "Train net_x2y for embedding: [epoch 169/200] train_loss:0.000000 Time:27.2914\n",
      "Train net_x2y for embedding: [epoch 170/200] train_loss:0.000000 Time:27.4455\n",
      "Train net_x2y for embedding: [epoch 171/200] train_loss:0.000000 Time:27.6001\n",
      "Train net_x2y for embedding: [epoch 172/200] train_loss:0.000000 Time:27.7542\n",
      "Train net_x2y for embedding: [epoch 173/200] train_loss:0.000000 Time:27.9084\n",
      "Train net_x2y for embedding: [epoch 174/200] train_loss:0.000000 Time:28.0631\n",
      "Train net_x2y for embedding: [epoch 175/200] train_loss:0.000000 Time:28.2175\n",
      "Train net_x2y for embedding: [epoch 176/200] train_loss:0.000000 Time:28.3723\n",
      "Train net_x2y for embedding: [epoch 177/200] train_loss:0.000000 Time:28.5267\n",
      "Train net_x2y for embedding: [epoch 178/200] train_loss:0.000000 Time:28.6810\n",
      "Train net_x2y for embedding: [epoch 179/200] train_loss:0.000000 Time:28.8352\n",
      "Train net_x2y for embedding: [epoch 180/200] train_loss:0.000000 Time:28.9900\n",
      "Train net_x2y for embedding: [epoch 181/200] train_loss:0.000000 Time:29.1443\n",
      "Train net_x2y for embedding: [epoch 182/200] train_loss:0.000000 Time:29.2988\n",
      "Train net_x2y for embedding: [epoch 183/200] train_loss:0.000000 Time:29.4530\n",
      "Train net_x2y for embedding: [epoch 184/200] train_loss:0.000000 Time:29.6074\n",
      "Train net_x2y for embedding: [epoch 185/200] train_loss:0.000000 Time:29.7618\n",
      "Train net_x2y for embedding: [epoch 186/200] train_loss:0.000000 Time:29.9162\n",
      "Train net_x2y for embedding: [epoch 187/200] train_loss:0.000000 Time:30.0707\n",
      "Train net_x2y for embedding: [epoch 188/200] train_loss:0.000000 Time:30.2254\n",
      "Train net_x2y for embedding: [epoch 189/200] train_loss:0.000000 Time:30.3797\n",
      "Train net_x2y for embedding: [epoch 190/200] train_loss:0.000000 Time:30.5340\n",
      "Train net_x2y for embedding: [epoch 191/200] train_loss:0.000000 Time:30.6885\n",
      "Train net_x2y for embedding: [epoch 192/200] train_loss:0.000000 Time:30.8430\n",
      "Train net_x2y for embedding: [epoch 193/200] train_loss:0.000000 Time:30.9974\n",
      "Train net_x2y for embedding: [epoch 194/200] train_loss:0.000000 Time:31.1522\n",
      "Train net_x2y for embedding: [epoch 195/200] train_loss:0.000000 Time:31.3063\n",
      "Train net_x2y for embedding: [epoch 196/200] train_loss:0.000000 Time:31.4609\n",
      "Train net_x2y for embedding: [epoch 197/200] train_loss:0.000000 Time:31.6154\n",
      "Train net_x2y for embedding: [epoch 198/200] train_loss:0.000000 Time:31.7698\n",
      "Train net_x2y for embedding: [epoch 199/200] train_loss:0.000000 Time:31.9240\n",
      "Train net_x2y for embedding: [epoch 200/200] train_loss:0.000000 Time:32.0790\n",
      "\n",
      " Start training net_y2h >>>\n",
      "\n",
      " Train net_y2h: [epoch 1/500] train_loss:0.053521 Time:0.0140\n",
      "\n",
      " Train net_y2h: [epoch 2/500] train_loss:0.033097 Time:0.0191\n",
      "\n",
      " Train net_y2h: [epoch 3/500] train_loss:0.012152 Time:0.0240\n",
      "\n",
      " Train net_y2h: [epoch 4/500] train_loss:0.007397 Time:0.0289\n",
      "\n",
      " Train net_y2h: [epoch 5/500] train_loss:0.017457 Time:0.0340\n",
      "\n",
      " Train net_y2h: [epoch 6/500] train_loss:0.006557 Time:0.0388\n",
      "\n",
      " Train net_y2h: [epoch 7/500] train_loss:0.016249 Time:0.0438\n",
      "\n",
      " Train net_y2h: [epoch 8/500] train_loss:0.007652 Time:0.0488\n",
      "\n",
      " Train net_y2h: [epoch 9/500] train_loss:0.007784 Time:0.0538\n",
      "\n",
      " Train net_y2h: [epoch 10/500] train_loss:0.007837 Time:0.0587\n",
      "\n",
      " Train net_y2h: [epoch 11/500] train_loss:0.002749 Time:0.0636\n",
      "\n",
      " Train net_y2h: [epoch 12/500] train_loss:0.006459 Time:0.0684\n",
      "\n",
      " Train net_y2h: [epoch 13/500] train_loss:0.001870 Time:0.0733\n",
      "\n",
      " Train net_y2h: [epoch 14/500] train_loss:0.003317 Time:0.0782\n",
      "\n",
      " Train net_y2h: [epoch 15/500] train_loss:0.003721 Time:0.0831\n",
      "\n",
      " Train net_y2h: [epoch 16/500] train_loss:0.004543 Time:0.0880\n",
      "\n",
      " Train net_y2h: [epoch 17/500] train_loss:0.001564 Time:0.0928\n",
      "\n",
      " Train net_y2h: [epoch 18/500] train_loss:0.002388 Time:0.0977\n",
      "\n",
      " Train net_y2h: [epoch 19/500] train_loss:0.001847 Time:0.1026\n",
      "\n",
      " Train net_y2h: [epoch 20/500] train_loss:0.002029 Time:0.1075\n",
      "\n",
      " Train net_y2h: [epoch 21/500] train_loss:0.002369 Time:0.1123\n",
      "\n",
      " Train net_y2h: [epoch 22/500] train_loss:0.001745 Time:0.1171\n",
      "\n",
      " Train net_y2h: [epoch 23/500] train_loss:0.001908 Time:0.1220\n",
      "\n",
      " Train net_y2h: [epoch 24/500] train_loss:0.002558 Time:0.1271\n",
      "\n",
      " Train net_y2h: [epoch 25/500] train_loss:0.001090 Time:0.1321\n",
      "\n",
      " Train net_y2h: [epoch 26/500] train_loss:0.001393 Time:0.1371\n",
      "\n",
      " Train net_y2h: [epoch 27/500] train_loss:0.000817 Time:0.1422\n",
      "\n",
      " Train net_y2h: [epoch 28/500] train_loss:0.000584 Time:0.1471\n",
      "\n",
      " Train net_y2h: [epoch 29/500] train_loss:0.001044 Time:0.1521\n",
      "\n",
      " Train net_y2h: [epoch 30/500] train_loss:0.000769 Time:0.1570\n",
      "\n",
      " Train net_y2h: [epoch 31/500] train_loss:0.000761 Time:0.1619\n",
      "\n",
      " Train net_y2h: [epoch 32/500] train_loss:0.000875 Time:0.1668\n",
      "\n",
      " Train net_y2h: [epoch 33/500] train_loss:0.000649 Time:0.1717\n",
      "\n",
      " Train net_y2h: [epoch 34/500] train_loss:0.000631 Time:0.1765\n",
      "\n",
      " Train net_y2h: [epoch 35/500] train_loss:0.000264 Time:0.1814\n",
      "\n",
      " Train net_y2h: [epoch 36/500] train_loss:0.000326 Time:0.1863\n",
      "\n",
      " Train net_y2h: [epoch 37/500] train_loss:0.000453 Time:0.1912\n",
      "\n",
      " Train net_y2h: [epoch 38/500] train_loss:0.000102 Time:0.1961\n",
      "\n",
      " Train net_y2h: [epoch 39/500] train_loss:0.000155 Time:0.2014\n",
      "\n",
      " Train net_y2h: [epoch 40/500] train_loss:0.000220 Time:0.2070\n",
      "\n",
      " Train net_y2h: [epoch 41/500] train_loss:0.000085 Time:0.2120\n",
      "\n",
      " Train net_y2h: [epoch 42/500] train_loss:0.000185 Time:0.2172\n",
      "\n",
      " Train net_y2h: [epoch 43/500] train_loss:0.000114 Time:0.2224\n",
      "\n",
      " Train net_y2h: [epoch 44/500] train_loss:0.000052 Time:0.2273\n",
      "\n",
      " Train net_y2h: [epoch 45/500] train_loss:0.000063 Time:0.2324\n",
      "\n",
      " Train net_y2h: [epoch 46/500] train_loss:0.000060 Time:0.2378\n",
      "\n",
      " Train net_y2h: [epoch 47/500] train_loss:0.000133 Time:0.2429\n",
      "\n",
      " Train net_y2h: [epoch 48/500] train_loss:0.000058 Time:0.2479\n",
      "\n",
      " Train net_y2h: [epoch 49/500] train_loss:0.000142 Time:0.2528\n",
      "\n",
      " Train net_y2h: [epoch 50/500] train_loss:0.000080 Time:0.2583\n",
      "\n",
      " Train net_y2h: [epoch 51/500] train_loss:0.000164 Time:0.2634\n",
      "\n",
      " Train net_y2h: [epoch 52/500] train_loss:0.000190 Time:0.2684\n",
      "\n",
      " Train net_y2h: [epoch 53/500] train_loss:0.000157 Time:0.2734\n",
      "\n",
      " Train net_y2h: [epoch 54/500] train_loss:0.000150 Time:0.2784\n",
      "\n",
      " Train net_y2h: [epoch 55/500] train_loss:0.000229 Time:0.2835\n",
      "\n",
      " Train net_y2h: [epoch 56/500] train_loss:0.000125 Time:0.2885\n",
      "\n",
      " Train net_y2h: [epoch 57/500] train_loss:0.000170 Time:0.2935\n",
      "\n",
      " Train net_y2h: [epoch 58/500] train_loss:0.000171 Time:0.2985\n",
      "\n",
      " Train net_y2h: [epoch 59/500] train_loss:0.000063 Time:0.3035\n",
      "\n",
      " Train net_y2h: [epoch 60/500] train_loss:0.000064 Time:0.3085\n",
      "\n",
      " Train net_y2h: [epoch 61/500] train_loss:0.000057 Time:0.3134\n",
      "\n",
      " Train net_y2h: [epoch 62/500] train_loss:0.000031 Time:0.3184\n",
      "\n",
      " Train net_y2h: [epoch 63/500] train_loss:0.000041 Time:0.3236\n",
      "\n",
      " Train net_y2h: [epoch 64/500] train_loss:0.000064 Time:0.3286\n",
      "\n",
      " Train net_y2h: [epoch 65/500] train_loss:0.000035 Time:0.3335\n",
      "\n",
      " Train net_y2h: [epoch 66/500] train_loss:0.000035 Time:0.3384\n",
      "\n",
      " Train net_y2h: [epoch 67/500] train_loss:0.000022 Time:0.3433\n",
      "\n",
      " Train net_y2h: [epoch 68/500] train_loss:0.000018 Time:0.3482\n",
      "\n",
      " Train net_y2h: [epoch 69/500] train_loss:0.000026 Time:0.3533\n",
      "\n",
      " Train net_y2h: [epoch 70/500] train_loss:0.000022 Time:0.3582\n",
      "\n",
      " Train net_y2h: [epoch 71/500] train_loss:0.000016 Time:0.3631\n",
      "\n",
      " Train net_y2h: [epoch 72/500] train_loss:0.000025 Time:0.3680\n",
      "\n",
      " Train net_y2h: [epoch 73/500] train_loss:0.000017 Time:0.3733\n",
      "\n",
      " Train net_y2h: [epoch 74/500] train_loss:0.000017 Time:0.3783\n",
      "\n",
      " Train net_y2h: [epoch 75/500] train_loss:0.000010 Time:0.3832\n",
      "\n",
      " Train net_y2h: [epoch 76/500] train_loss:0.000016 Time:0.3884\n",
      "\n",
      " Train net_y2h: [epoch 77/500] train_loss:0.000046 Time:0.3935\n",
      "\n",
      " Train net_y2h: [epoch 78/500] train_loss:0.000022 Time:0.3984\n",
      "\n",
      " Train net_y2h: [epoch 79/500] train_loss:0.000018 Time:0.4039\n",
      "\n",
      " Train net_y2h: [epoch 80/500] train_loss:0.000027 Time:0.4095\n",
      "\n",
      " Train net_y2h: [epoch 81/500] train_loss:0.000056 Time:0.4146\n",
      "\n",
      " Train net_y2h: [epoch 82/500] train_loss:0.000016 Time:0.4197\n",
      "\n",
      " Train net_y2h: [epoch 83/500] train_loss:0.000012 Time:0.4248\n",
      "\n",
      " Train net_y2h: [epoch 84/500] train_loss:0.000045 Time:0.4298\n",
      "\n",
      " Train net_y2h: [epoch 85/500] train_loss:0.000024 Time:0.4352\n",
      "\n",
      " Train net_y2h: [epoch 86/500] train_loss:0.000061 Time:0.4401\n",
      "\n",
      " Train net_y2h: [epoch 87/500] train_loss:0.000016 Time:0.4451\n",
      "\n",
      " Train net_y2h: [epoch 88/500] train_loss:0.000040 Time:0.4501\n",
      "\n",
      " Train net_y2h: [epoch 89/500] train_loss:0.000045 Time:0.4550\n",
      "\n",
      " Train net_y2h: [epoch 90/500] train_loss:0.000068 Time:0.4599\n",
      "\n",
      " Train net_y2h: [epoch 91/500] train_loss:0.000043 Time:0.4648\n",
      "\n",
      " Train net_y2h: [epoch 92/500] train_loss:0.000044 Time:0.4697\n",
      "\n",
      " Train net_y2h: [epoch 93/500] train_loss:0.000030 Time:0.4748\n",
      "\n",
      " Train net_y2h: [epoch 94/500] train_loss:0.000027 Time:0.4798\n",
      "\n",
      " Train net_y2h: [epoch 95/500] train_loss:0.000018 Time:0.4849\n",
      "\n",
      " Train net_y2h: [epoch 96/500] train_loss:0.000028 Time:0.4898\n",
      "\n",
      " Train net_y2h: [epoch 97/500] train_loss:0.000023 Time:0.4947\n",
      "\n",
      " Train net_y2h: [epoch 98/500] train_loss:0.000056 Time:0.4999\n",
      "\n",
      " Train net_y2h: [epoch 99/500] train_loss:0.000024 Time:0.5049\n",
      "\n",
      " Train net_y2h: [epoch 100/500] train_loss:0.000100 Time:0.5098\n",
      "\n",
      " Train net_y2h: [epoch 101/500] train_loss:0.000073 Time:0.5148\n",
      "\n",
      " Train net_y2h: [epoch 102/500] train_loss:0.000122 Time:0.5196\n",
      "\n",
      " Train net_y2h: [epoch 103/500] train_loss:0.000046 Time:0.5247\n",
      "\n",
      " Train net_y2h: [epoch 104/500] train_loss:0.000119 Time:0.5296\n",
      "\n",
      " Train net_y2h: [epoch 105/500] train_loss:0.000118 Time:0.5346\n",
      "\n",
      " Train net_y2h: [epoch 106/500] train_loss:0.000042 Time:0.5395\n",
      "\n",
      " Train net_y2h: [epoch 107/500] train_loss:0.000046 Time:0.5444\n",
      "\n",
      " Train net_y2h: [epoch 108/500] train_loss:0.000031 Time:0.5493\n",
      "\n",
      " Train net_y2h: [epoch 109/500] train_loss:0.000062 Time:0.5544\n",
      "\n",
      " Train net_y2h: [epoch 110/500] train_loss:0.000026 Time:0.5595\n",
      "\n",
      " Train net_y2h: [epoch 111/500] train_loss:0.000039 Time:0.5646\n",
      "\n",
      " Train net_y2h: [epoch 112/500] train_loss:0.000025 Time:0.5697\n",
      "\n",
      " Train net_y2h: [epoch 113/500] train_loss:0.000037 Time:0.5748\n",
      "\n",
      " Train net_y2h: [epoch 114/500] train_loss:0.000024 Time:0.5798\n",
      "\n",
      " Train net_y2h: [epoch 115/500] train_loss:0.000014 Time:0.5847\n",
      "\n",
      " Train net_y2h: [epoch 116/500] train_loss:0.000036 Time:0.5896\n",
      "\n",
      " Train net_y2h: [epoch 117/500] train_loss:0.000016 Time:0.5945\n",
      "\n",
      " Train net_y2h: [epoch 118/500] train_loss:0.000039 Time:0.5995\n",
      "\n",
      " Train net_y2h: [epoch 119/500] train_loss:0.000014 Time:0.6045\n",
      "\n",
      " Train net_y2h: [epoch 120/500] train_loss:0.000041 Time:0.6107\n",
      "\n",
      " Train net_y2h: [epoch 121/500] train_loss:0.000013 Time:0.6159\n",
      "\n",
      " Train net_y2h: [epoch 122/500] train_loss:0.000053 Time:0.6214\n",
      "\n",
      " Train net_y2h: [epoch 123/500] train_loss:0.000007 Time:0.6265\n",
      "\n",
      " Train net_y2h: [epoch 124/500] train_loss:0.000090 Time:0.6316\n",
      "\n",
      " Train net_y2h: [epoch 125/500] train_loss:0.000047 Time:0.6368\n",
      "\n",
      " Train net_y2h: [epoch 126/500] train_loss:0.000036 Time:0.6418\n",
      "\n",
      " Train net_y2h: [epoch 127/500] train_loss:0.000012 Time:0.6467\n",
      "\n",
      " Train net_y2h: [epoch 128/500] train_loss:0.000066 Time:0.6515\n",
      "\n",
      " Train net_y2h: [epoch 129/500] train_loss:0.000019 Time:0.6564\n",
      "\n",
      " Train net_y2h: [epoch 130/500] train_loss:0.000045 Time:0.6613\n",
      "\n",
      " Train net_y2h: [epoch 131/500] train_loss:0.000015 Time:0.6662\n",
      "\n",
      " Train net_y2h: [epoch 132/500] train_loss:0.000052 Time:0.6710\n",
      "\n",
      " Train net_y2h: [epoch 133/500] train_loss:0.000036 Time:0.6760\n",
      "\n",
      " Train net_y2h: [epoch 134/500] train_loss:0.000036 Time:0.6808\n",
      "\n",
      " Train net_y2h: [epoch 135/500] train_loss:0.000007 Time:0.6856\n",
      "\n",
      " Train net_y2h: [epoch 136/500] train_loss:0.000054 Time:0.6905\n",
      "\n",
      " Train net_y2h: [epoch 137/500] train_loss:0.000017 Time:0.6953\n",
      "\n",
      " Train net_y2h: [epoch 138/500] train_loss:0.000062 Time:0.7001\n",
      "\n",
      " Train net_y2h: [epoch 139/500] train_loss:0.000054 Time:0.7049\n",
      "\n",
      " Train net_y2h: [epoch 140/500] train_loss:0.000038 Time:0.7098\n",
      "\n",
      " Train net_y2h: [epoch 141/500] train_loss:0.000042 Time:0.7146\n",
      "\n",
      " Train net_y2h: [epoch 142/500] train_loss:0.000048 Time:0.7194\n",
      "\n",
      " Train net_y2h: [epoch 143/500] train_loss:0.000040 Time:0.7243\n",
      "\n",
      " Train net_y2h: [epoch 144/500] train_loss:0.000056 Time:0.7292\n",
      "\n",
      " Train net_y2h: [epoch 145/500] train_loss:0.000018 Time:0.7342\n",
      "\n",
      " Train net_y2h: [epoch 146/500] train_loss:0.000023 Time:0.7390\n",
      "\n",
      " Train net_y2h: [epoch 147/500] train_loss:0.000019 Time:0.7438\n",
      "\n",
      " Train net_y2h: [epoch 148/500] train_loss:0.000017 Time:0.7486\n",
      "\n",
      " Train net_y2h: [epoch 149/500] train_loss:0.000008 Time:0.7535\n",
      "\n",
      " Train net_y2h: [epoch 150/500] train_loss:0.000015 Time:0.7583\n",
      "\n",
      " Train net_y2h: [epoch 151/500] train_loss:0.000015 Time:0.7631\n",
      "\n",
      " Train net_y2h: [epoch 152/500] train_loss:0.000013 Time:0.7680\n",
      "\n",
      " Train net_y2h: [epoch 153/500] train_loss:0.000011 Time:0.7727\n",
      "\n",
      " Train net_y2h: [epoch 154/500] train_loss:0.000007 Time:0.7775\n",
      "\n",
      " Train net_y2h: [epoch 155/500] train_loss:0.000004 Time:0.7824\n",
      "\n",
      " Train net_y2h: [epoch 156/500] train_loss:0.000018 Time:0.7873\n",
      "\n",
      " Train net_y2h: [epoch 157/500] train_loss:0.000004 Time:0.7921\n",
      "\n",
      " Train net_y2h: [epoch 158/500] train_loss:0.000006 Time:0.7970\n",
      "\n",
      " Train net_y2h: [epoch 159/500] train_loss:0.000005 Time:0.8019\n",
      "\n",
      " Train net_y2h: [epoch 160/500] train_loss:0.000004 Time:0.8067\n",
      "\n",
      " Train net_y2h: [epoch 161/500] train_loss:0.000004 Time:0.8119\n",
      "\n",
      " Train net_y2h: [epoch 162/500] train_loss:0.000006 Time:0.8175\n",
      "\n",
      " Train net_y2h: [epoch 163/500] train_loss:0.000008 Time:0.8226\n",
      "\n",
      " Train net_y2h: [epoch 164/500] train_loss:0.000010 Time:0.8279\n",
      "\n",
      " Train net_y2h: [epoch 165/500] train_loss:0.000007 Time:0.8332\n",
      "\n",
      " Train net_y2h: [epoch 166/500] train_loss:0.000005 Time:0.8385\n",
      "\n",
      " Train net_y2h: [epoch 167/500] train_loss:0.000017 Time:0.8435\n",
      "\n",
      " Train net_y2h: [epoch 168/500] train_loss:0.000016 Time:0.8485\n",
      "\n",
      " Train net_y2h: [epoch 169/500] train_loss:0.000008 Time:0.8534\n",
      "\n",
      " Train net_y2h: [epoch 170/500] train_loss:0.000008 Time:0.8583\n",
      "\n",
      " Train net_y2h: [epoch 171/500] train_loss:0.000008 Time:0.8631\n",
      "\n",
      " Train net_y2h: [epoch 172/500] train_loss:0.000008 Time:0.8681\n",
      "\n",
      " Train net_y2h: [epoch 173/500] train_loss:0.000004 Time:0.8729\n",
      "\n",
      " Train net_y2h: [epoch 174/500] train_loss:0.000007 Time:0.8778\n",
      "\n",
      " Train net_y2h: [epoch 175/500] train_loss:0.000004 Time:0.8826\n",
      "\n",
      " Train net_y2h: [epoch 176/500] train_loss:0.000005 Time:0.8875\n",
      "\n",
      " Train net_y2h: [epoch 177/500] train_loss:0.000004 Time:0.8924\n",
      "\n",
      " Train net_y2h: [epoch 178/500] train_loss:0.000006 Time:0.8973\n",
      "\n",
      " Train net_y2h: [epoch 179/500] train_loss:0.000012 Time:0.9024\n",
      "\n",
      " Train net_y2h: [epoch 180/500] train_loss:0.000003 Time:0.9073\n",
      "\n",
      " Train net_y2h: [epoch 181/500] train_loss:0.000002 Time:0.9121\n",
      "\n",
      " Train net_y2h: [epoch 182/500] train_loss:0.000004 Time:0.9170\n",
      "\n",
      " Train net_y2h: [epoch 183/500] train_loss:0.000011 Time:0.9219\n",
      "\n",
      " Train net_y2h: [epoch 184/500] train_loss:0.000008 Time:0.9268\n",
      "\n",
      " Train net_y2h: [epoch 185/500] train_loss:0.000002 Time:0.9317\n",
      "\n",
      " Train net_y2h: [epoch 186/500] train_loss:0.000003 Time:0.9367\n",
      "\n",
      " Train net_y2h: [epoch 187/500] train_loss:0.000003 Time:0.9417\n",
      "\n",
      " Train net_y2h: [epoch 188/500] train_loss:0.000008 Time:0.9465\n",
      "\n",
      " Train net_y2h: [epoch 189/500] train_loss:0.000004 Time:0.9514\n",
      "\n",
      " Train net_y2h: [epoch 190/500] train_loss:0.000002 Time:0.9563\n",
      "\n",
      " Train net_y2h: [epoch 191/500] train_loss:0.000003 Time:0.9613\n",
      "\n",
      " Train net_y2h: [epoch 192/500] train_loss:0.000004 Time:0.9663\n",
      "\n",
      " Train net_y2h: [epoch 193/500] train_loss:0.000008 Time:0.9713\n",
      "\n",
      " Train net_y2h: [epoch 194/500] train_loss:0.000004 Time:0.9762\n",
      "\n",
      " Train net_y2h: [epoch 195/500] train_loss:0.000003 Time:0.9812\n",
      "\n",
      " Train net_y2h: [epoch 196/500] train_loss:0.000003 Time:0.9862\n",
      "\n",
      " Train net_y2h: [epoch 197/500] train_loss:0.000004 Time:0.9911\n",
      "\n",
      " Train net_y2h: [epoch 198/500] train_loss:0.000004 Time:0.9961\n",
      "\n",
      " Train net_y2h: [epoch 199/500] train_loss:0.000003 Time:1.0011\n",
      "\n",
      " Train net_y2h: [epoch 200/500] train_loss:0.000004 Time:1.0060\n",
      "\n",
      " Train net_y2h: [epoch 201/500] train_loss:0.000004 Time:1.0109\n",
      "\n",
      " Train net_y2h: [epoch 202/500] train_loss:0.000004 Time:1.0165\n",
      "\n",
      " Train net_y2h: [epoch 203/500] train_loss:0.000008 Time:1.0217\n",
      "\n",
      " Train net_y2h: [epoch 204/500] train_loss:0.000003 Time:1.0270\n",
      "\n",
      " Train net_y2h: [epoch 205/500] train_loss:0.000011 Time:1.0322\n",
      "\n",
      " Train net_y2h: [epoch 206/500] train_loss:0.000002 Time:1.0372\n",
      "\n",
      " Train net_y2h: [epoch 207/500] train_loss:0.000004 Time:1.0424\n",
      "\n",
      " Train net_y2h: [epoch 208/500] train_loss:0.000009 Time:1.0476\n",
      "\n",
      " Train net_y2h: [epoch 209/500] train_loss:0.000003 Time:1.0526\n",
      "\n",
      " Train net_y2h: [epoch 210/500] train_loss:0.000017 Time:1.0577\n",
      "\n",
      " Train net_y2h: [epoch 211/500] train_loss:0.000004 Time:1.0627\n",
      "\n",
      " Train net_y2h: [epoch 212/500] train_loss:0.000010 Time:1.0676\n",
      "\n",
      " Train net_y2h: [epoch 213/500] train_loss:0.000007 Time:1.0726\n",
      "\n",
      " Train net_y2h: [epoch 214/500] train_loss:0.000004 Time:1.0775\n",
      "\n",
      " Train net_y2h: [epoch 215/500] train_loss:0.000007 Time:1.0825\n",
      "\n",
      " Train net_y2h: [epoch 216/500] train_loss:0.000016 Time:1.0874\n",
      "\n",
      " Train net_y2h: [epoch 217/500] train_loss:0.000007 Time:1.0945\n",
      "\n",
      " Train net_y2h: [epoch 218/500] train_loss:0.000003 Time:1.1020\n",
      "\n",
      " Train net_y2h: [epoch 219/500] train_loss:0.000003 Time:1.1094\n",
      "\n",
      " Train net_y2h: [epoch 220/500] train_loss:0.000008 Time:1.1167\n",
      "\n",
      " Train net_y2h: [epoch 221/500] train_loss:0.000003 Time:1.1241\n",
      "\n",
      " Train net_y2h: [epoch 222/500] train_loss:0.000005 Time:1.1315\n",
      "\n",
      " Train net_y2h: [epoch 223/500] train_loss:0.000005 Time:1.1390\n",
      "\n",
      " Train net_y2h: [epoch 224/500] train_loss:0.000009 Time:1.1466\n",
      "\n",
      " Train net_y2h: [epoch 225/500] train_loss:0.000008 Time:1.1540\n",
      "\n",
      " Train net_y2h: [epoch 226/500] train_loss:0.000003 Time:1.1644\n",
      "\n",
      " Train net_y2h: [epoch 227/500] train_loss:0.000011 Time:1.1748\n",
      "\n",
      " Train net_y2h: [epoch 228/500] train_loss:0.000006 Time:1.1823\n",
      "\n",
      " Train net_y2h: [epoch 229/500] train_loss:0.000005 Time:1.1885\n",
      "\n",
      " Train net_y2h: [epoch 230/500] train_loss:0.000013 Time:1.1958\n",
      "\n",
      " Train net_y2h: [epoch 231/500] train_loss:0.000004 Time:1.2063\n",
      "\n",
      " Train net_y2h: [epoch 232/500] train_loss:0.000007 Time:1.2156\n",
      "\n",
      " Train net_y2h: [epoch 233/500] train_loss:0.000004 Time:1.2246\n",
      "\n",
      " Train net_y2h: [epoch 234/500] train_loss:0.000011 Time:1.2321\n",
      "\n",
      " Train net_y2h: [epoch 235/500] train_loss:0.000004 Time:1.2378\n",
      "\n",
      " Train net_y2h: [epoch 236/500] train_loss:0.000003 Time:1.2429\n",
      "\n",
      " Train net_y2h: [epoch 237/500] train_loss:0.000004 Time:1.2480\n",
      "\n",
      " Train net_y2h: [epoch 238/500] train_loss:0.000002 Time:1.2532\n",
      "\n",
      " Train net_y2h: [epoch 239/500] train_loss:0.000003 Time:1.2583\n",
      "\n",
      " Train net_y2h: [epoch 240/500] train_loss:0.000003 Time:1.2633\n",
      "\n",
      " Train net_y2h: [epoch 241/500] train_loss:0.000003 Time:1.2681\n",
      "\n",
      " Train net_y2h: [epoch 242/500] train_loss:0.000003 Time:1.2731\n",
      "\n",
      " Train net_y2h: [epoch 243/500] train_loss:0.000007 Time:1.2780\n",
      "\n",
      " Train net_y2h: [epoch 244/500] train_loss:0.000003 Time:1.2828\n",
      "\n",
      " Train net_y2h: [epoch 245/500] train_loss:0.000004 Time:1.2878\n",
      "\n",
      " Train net_y2h: [epoch 246/500] train_loss:0.000003 Time:1.2928\n",
      "\n",
      " Train net_y2h: [epoch 247/500] train_loss:0.000007 Time:1.2978\n",
      "\n",
      " Train net_y2h: [epoch 248/500] train_loss:0.000003 Time:1.3027\n",
      "\n",
      " Train net_y2h: [epoch 249/500] train_loss:0.000003 Time:1.3077\n",
      "\n",
      " Train net_y2h: [epoch 250/500] train_loss:0.000006 Time:1.3126\n",
      "\n",
      " Train net_y2h: [epoch 251/500] train_loss:0.000006 Time:1.3175\n",
      "\n",
      " Train net_y2h: [epoch 252/500] train_loss:0.000006 Time:1.3223\n",
      "\n",
      " Train net_y2h: [epoch 253/500] train_loss:0.000009 Time:1.3275\n",
      "\n",
      " Train net_y2h: [epoch 254/500] train_loss:0.000005 Time:1.3328\n",
      "\n",
      " Train net_y2h: [epoch 255/500] train_loss:0.000006 Time:1.3377\n",
      "\n",
      " Train net_y2h: [epoch 256/500] train_loss:0.000003 Time:1.3427\n",
      "\n",
      " Train net_y2h: [epoch 257/500] train_loss:0.000003 Time:1.3475\n",
      "\n",
      " Train net_y2h: [epoch 258/500] train_loss:0.000003 Time:1.3525\n",
      "\n",
      " Train net_y2h: [epoch 259/500] train_loss:0.000008 Time:1.3574\n",
      "\n",
      " Train net_y2h: [epoch 260/500] train_loss:0.000005 Time:1.3623\n",
      "\n",
      " Train net_y2h: [epoch 261/500] train_loss:0.000005 Time:1.3671\n",
      "\n",
      " Train net_y2h: [epoch 262/500] train_loss:0.000004 Time:1.3720\n",
      "\n",
      " Train net_y2h: [epoch 263/500] train_loss:0.000009 Time:1.3770\n",
      "\n",
      " Train net_y2h: [epoch 264/500] train_loss:0.000009 Time:1.3819\n",
      "\n",
      " Train net_y2h: [epoch 265/500] train_loss:0.000003 Time:1.3868\n",
      "\n",
      " Train net_y2h: [epoch 266/500] train_loss:0.000003 Time:1.3919\n",
      "\n",
      " Train net_y2h: [epoch 267/500] train_loss:0.000003 Time:1.3969\n",
      "\n",
      " Train net_y2h: [epoch 268/500] train_loss:0.000007 Time:1.4018\n",
      "\n",
      " Train net_y2h: [epoch 269/500] train_loss:0.000003 Time:1.4067\n",
      "\n",
      " Train net_y2h: [epoch 270/500] train_loss:0.000007 Time:1.4116\n",
      "\n",
      " Train net_y2h: [epoch 271/500] train_loss:0.000004 Time:1.4165\n",
      "\n",
      " Train net_y2h: [epoch 272/500] train_loss:0.000011 Time:1.4214\n",
      "\n",
      " Train net_y2h: [epoch 273/500] train_loss:0.000007 Time:1.4266\n",
      "\n",
      " Train net_y2h: [epoch 274/500] train_loss:0.000003 Time:1.4320\n",
      "\n",
      " Train net_y2h: [epoch 275/500] train_loss:0.000007 Time:1.4370\n",
      "\n",
      " Train net_y2h: [epoch 276/500] train_loss:0.000006 Time:1.4423\n",
      "\n",
      " Train net_y2h: [epoch 277/500] train_loss:0.000003 Time:1.4477\n",
      "\n",
      " Train net_y2h: [epoch 278/500] train_loss:0.000010 Time:1.4527\n",
      "\n",
      " Train net_y2h: [epoch 279/500] train_loss:0.000013 Time:1.4577\n",
      "\n",
      " Train net_y2h: [epoch 280/500] train_loss:0.000003 Time:1.4626\n",
      "\n",
      " Train net_y2h: [epoch 281/500] train_loss:0.000002 Time:1.4675\n",
      "\n",
      " Train net_y2h: [epoch 282/500] train_loss:0.000003 Time:1.4724\n",
      "\n",
      " Train net_y2h: [epoch 283/500] train_loss:0.000010 Time:1.4773\n",
      "\n",
      " Train net_y2h: [epoch 284/500] train_loss:0.000003 Time:1.4822\n",
      "\n",
      " Train net_y2h: [epoch 285/500] train_loss:0.000004 Time:1.4872\n",
      "\n",
      " Train net_y2h: [epoch 286/500] train_loss:0.000003 Time:1.4922\n",
      "\n",
      " Train net_y2h: [epoch 287/500] train_loss:0.000003 Time:1.4971\n",
      "\n",
      " Train net_y2h: [epoch 288/500] train_loss:0.000003 Time:1.5021\n",
      "\n",
      " Train net_y2h: [epoch 289/500] train_loss:0.000006 Time:1.5071\n",
      "\n",
      " Train net_y2h: [epoch 290/500] train_loss:0.000008 Time:1.5120\n",
      "\n",
      " Train net_y2h: [epoch 291/500] train_loss:0.000003 Time:1.5169\n",
      "\n",
      " Train net_y2h: [epoch 292/500] train_loss:0.000003 Time:1.5218\n",
      "\n",
      " Train net_y2h: [epoch 293/500] train_loss:0.000004 Time:1.5267\n",
      "\n",
      " Train net_y2h: [epoch 294/500] train_loss:0.000006 Time:1.5316\n",
      "\n",
      " Train net_y2h: [epoch 295/500] train_loss:0.000003 Time:1.5366\n",
      "\n",
      " Train net_y2h: [epoch 296/500] train_loss:0.000014 Time:1.5415\n",
      "\n",
      " Train net_y2h: [epoch 297/500] train_loss:0.000004 Time:1.5463\n",
      "\n",
      " Train net_y2h: [epoch 298/500] train_loss:0.000003 Time:1.5512\n",
      "\n",
      " Train net_y2h: [epoch 299/500] train_loss:0.000002 Time:1.5562\n",
      "\n",
      " Train net_y2h: [epoch 300/500] train_loss:0.000004 Time:1.5612\n",
      "\n",
      " Train net_y2h: [epoch 301/500] train_loss:0.000007 Time:1.5661\n",
      "\n",
      " Train net_y2h: [epoch 302/500] train_loss:0.000006 Time:1.5711\n",
      "\n",
      " Train net_y2h: [epoch 303/500] train_loss:0.000004 Time:1.5760\n",
      "\n",
      " Train net_y2h: [epoch 304/500] train_loss:0.000006 Time:1.5811\n",
      "\n",
      " Train net_y2h: [epoch 305/500] train_loss:0.000006 Time:1.5861\n",
      "\n",
      " Train net_y2h: [epoch 306/500] train_loss:0.000002 Time:1.5910\n",
      "\n",
      " Train net_y2h: [epoch 307/500] train_loss:0.000004 Time:1.5958\n",
      "\n",
      " Train net_y2h: [epoch 308/500] train_loss:0.000009 Time:1.6008\n",
      "\n",
      " Train net_y2h: [epoch 309/500] train_loss:0.000004 Time:1.6057\n",
      "\n",
      " Train net_y2h: [epoch 310/500] train_loss:0.000005 Time:1.6108\n",
      "\n",
      " Train net_y2h: [epoch 311/500] train_loss:0.000004 Time:1.6157\n",
      "\n",
      " Train net_y2h: [epoch 312/500] train_loss:0.000003 Time:1.6206\n",
      "\n",
      " Train net_y2h: [epoch 313/500] train_loss:0.000003 Time:1.6255\n",
      "\n",
      " Train net_y2h: [epoch 314/500] train_loss:0.000003 Time:1.6310\n",
      "\n",
      " Train net_y2h: [epoch 315/500] train_loss:0.000007 Time:1.6362\n",
      "\n",
      " Train net_y2h: [epoch 316/500] train_loss:0.000004 Time:1.6415\n",
      "\n",
      " Train net_y2h: [epoch 317/500] train_loss:0.000003 Time:1.6465\n",
      "\n",
      " Train net_y2h: [epoch 318/500] train_loss:0.000010 Time:1.6515\n",
      "\n",
      " Train net_y2h: [epoch 319/500] train_loss:0.000002 Time:1.6564\n",
      "\n",
      " Train net_y2h: [epoch 320/500] train_loss:0.000010 Time:1.6614\n",
      "\n",
      " Train net_y2h: [epoch 321/500] train_loss:0.000006 Time:1.6663\n",
      "\n",
      " Train net_y2h: [epoch 322/500] train_loss:0.000004 Time:1.6711\n",
      "\n",
      " Train net_y2h: [epoch 323/500] train_loss:0.000006 Time:1.6761\n",
      "\n",
      " Train net_y2h: [epoch 324/500] train_loss:0.000006 Time:1.6810\n",
      "\n",
      " Train net_y2h: [epoch 325/500] train_loss:0.000013 Time:1.6860\n",
      "\n",
      " Train net_y2h: [epoch 326/500] train_loss:0.000006 Time:1.6910\n",
      "\n",
      " Train net_y2h: [epoch 327/500] train_loss:0.000007 Time:1.6960\n",
      "\n",
      " Train net_y2h: [epoch 328/500] train_loss:0.000004 Time:1.7009\n",
      "\n",
      " Train net_y2h: [epoch 329/500] train_loss:0.000003 Time:1.7059\n",
      "\n",
      " Train net_y2h: [epoch 330/500] train_loss:0.000003 Time:1.7109\n",
      "\n",
      " Train net_y2h: [epoch 331/500] train_loss:0.000007 Time:1.7158\n",
      "\n",
      " Train net_y2h: [epoch 332/500] train_loss:0.000011 Time:1.7207\n",
      "\n",
      " Train net_y2h: [epoch 333/500] train_loss:0.000008 Time:1.7256\n",
      "\n",
      " Train net_y2h: [epoch 334/500] train_loss:0.000007 Time:1.7304\n",
      "\n",
      " Train net_y2h: [epoch 335/500] train_loss:0.000010 Time:1.7353\n",
      "\n",
      " Train net_y2h: [epoch 336/500] train_loss:0.000008 Time:1.7402\n",
      "\n",
      " Train net_y2h: [epoch 337/500] train_loss:0.000011 Time:1.7451\n",
      "\n",
      " Train net_y2h: [epoch 338/500] train_loss:0.000003 Time:1.7500\n",
      "\n",
      " Train net_y2h: [epoch 339/500] train_loss:0.000007 Time:1.7548\n",
      "\n",
      " Train net_y2h: [epoch 340/500] train_loss:0.000006 Time:1.7597\n",
      "\n",
      " Train net_y2h: [epoch 341/500] train_loss:0.000006 Time:1.7645\n",
      "\n",
      " Train net_y2h: [epoch 342/500] train_loss:0.000004 Time:1.7694\n",
      "\n",
      " Train net_y2h: [epoch 343/500] train_loss:0.000006 Time:1.7743\n",
      "\n",
      " Train net_y2h: [epoch 344/500] train_loss:0.000003 Time:1.7792\n",
      "\n",
      " Train net_y2h: [epoch 345/500] train_loss:0.000004 Time:1.7841\n",
      "\n",
      " Train net_y2h: [epoch 346/500] train_loss:0.000004 Time:1.7890\n",
      "\n",
      " Train net_y2h: [epoch 347/500] train_loss:0.000003 Time:1.7945\n",
      "\n",
      " Train net_y2h: [epoch 348/500] train_loss:0.000004 Time:1.8023\n",
      "\n",
      " Train net_y2h: [epoch 349/500] train_loss:0.000003 Time:1.8098\n",
      "\n",
      " Train net_y2h: [epoch 350/500] train_loss:0.000003 Time:1.8170\n",
      "\n",
      " Train net_y2h: [epoch 351/500] train_loss:0.000003 Time:1.8244\n",
      "\n",
      " Train net_y2h: [epoch 352/500] train_loss:0.000006 Time:1.8323\n",
      "\n",
      " Train net_y2h: [epoch 353/500] train_loss:0.000003 Time:1.8400\n",
      "\n",
      " Train net_y2h: [epoch 354/500] train_loss:0.000003 Time:1.8475\n",
      "\n",
      " Train net_y2h: [epoch 355/500] train_loss:0.000003 Time:1.8548\n",
      "\n",
      " Train net_y2h: [epoch 356/500] train_loss:0.000003 Time:1.8622\n",
      "\n",
      " Train net_y2h: [epoch 357/500] train_loss:0.000007 Time:1.8698\n",
      "\n",
      " Train net_y2h: [epoch 358/500] train_loss:0.000005 Time:1.8771\n",
      "\n",
      " Train net_y2h: [epoch 359/500] train_loss:0.000007 Time:1.8842\n",
      "\n",
      " Train net_y2h: [epoch 360/500] train_loss:0.000003 Time:1.8904\n",
      "\n",
      " Train net_y2h: [epoch 361/500] train_loss:0.000009 Time:1.8985\n",
      "\n",
      " Train net_y2h: [epoch 362/500] train_loss:0.000002 Time:1.9065\n",
      "\n",
      " Train net_y2h: [epoch 363/500] train_loss:0.000003 Time:1.9145\n",
      "\n",
      " Train net_y2h: [epoch 364/500] train_loss:0.000003 Time:1.9225\n",
      "\n",
      " Train net_y2h: [epoch 365/500] train_loss:0.000009 Time:1.9301\n",
      "\n",
      " Train net_y2h: [epoch 366/500] train_loss:0.000002 Time:1.9358\n",
      "\n",
      " Train net_y2h: [epoch 367/500] train_loss:0.000003 Time:1.9410\n",
      "\n",
      " Train net_y2h: [epoch 368/500] train_loss:0.000006 Time:1.9462\n",
      "\n",
      " Train net_y2h: [epoch 369/500] train_loss:0.000006 Time:1.9515\n",
      "\n",
      " Train net_y2h: [epoch 370/500] train_loss:0.000003 Time:1.9565\n",
      "\n",
      " Train net_y2h: [epoch 371/500] train_loss:0.000012 Time:1.9614\n",
      "\n",
      " Train net_y2h: [epoch 372/500] train_loss:0.000006 Time:1.9664\n",
      "\n",
      " Train net_y2h: [epoch 373/500] train_loss:0.000003 Time:1.9714\n",
      "\n",
      " Train net_y2h: [epoch 374/500] train_loss:0.000003 Time:1.9763\n",
      "\n",
      " Train net_y2h: [epoch 375/500] train_loss:0.000003 Time:1.9813\n",
      "\n",
      " Train net_y2h: [epoch 376/500] train_loss:0.000004 Time:1.9863\n",
      "\n",
      " Train net_y2h: [epoch 377/500] train_loss:0.000013 Time:1.9912\n",
      "\n",
      " Train net_y2h: [epoch 378/500] train_loss:0.000007 Time:1.9962\n",
      "\n",
      " Train net_y2h: [epoch 379/500] train_loss:0.000004 Time:2.0011\n",
      "\n",
      " Train net_y2h: [epoch 380/500] train_loss:0.000004 Time:2.0061\n",
      "\n",
      " Train net_y2h: [epoch 381/500] train_loss:0.000003 Time:2.0111\n",
      "\n",
      " Train net_y2h: [epoch 382/500] train_loss:0.000014 Time:2.0160\n",
      "\n",
      " Train net_y2h: [epoch 383/500] train_loss:0.000007 Time:2.0210\n",
      "\n",
      " Train net_y2h: [epoch 384/500] train_loss:0.000003 Time:2.0259\n",
      "\n",
      " Train net_y2h: [epoch 385/500] train_loss:0.000003 Time:2.0308\n",
      "\n",
      " Train net_y2h: [epoch 386/500] train_loss:0.000007 Time:2.0362\n",
      "\n",
      " Train net_y2h: [epoch 387/500] train_loss:0.000011 Time:2.0414\n",
      "\n",
      " Train net_y2h: [epoch 388/500] train_loss:0.000003 Time:2.0464\n",
      "\n",
      " Train net_y2h: [epoch 389/500] train_loss:0.000003 Time:2.0513\n",
      "\n",
      " Train net_y2h: [epoch 390/500] train_loss:0.000003 Time:2.0564\n",
      "\n",
      " Train net_y2h: [epoch 391/500] train_loss:0.000009 Time:2.0612\n",
      "\n",
      " Train net_y2h: [epoch 392/500] train_loss:0.000010 Time:2.0663\n",
      "\n",
      " Train net_y2h: [epoch 393/500] train_loss:0.000003 Time:2.0712\n",
      "\n",
      " Train net_y2h: [epoch 394/500] train_loss:0.000007 Time:2.0762\n",
      "\n",
      " Train net_y2h: [epoch 395/500] train_loss:0.000002 Time:2.0811\n",
      "\n",
      " Train net_y2h: [epoch 396/500] train_loss:0.000003 Time:2.0860\n",
      "\n",
      " Train net_y2h: [epoch 397/500] train_loss:0.000003 Time:2.0908\n",
      "\n",
      " Train net_y2h: [epoch 398/500] train_loss:0.000003 Time:2.0957\n",
      "\n",
      " Train net_y2h: [epoch 399/500] train_loss:0.000004 Time:2.1005\n",
      "\n",
      " Train net_y2h: [epoch 400/500] train_loss:0.000003 Time:2.1054\n",
      "\n",
      " Train net_y2h: [epoch 401/500] train_loss:0.000004 Time:2.1104\n",
      "\n",
      " Train net_y2h: [epoch 402/500] train_loss:0.000003 Time:2.1153\n",
      "\n",
      " Train net_y2h: [epoch 403/500] train_loss:0.000003 Time:2.1202\n",
      "\n",
      " Train net_y2h: [epoch 404/500] train_loss:0.000009 Time:2.1252\n",
      "\n",
      " Train net_y2h: [epoch 405/500] train_loss:0.000014 Time:2.1301\n",
      "\n",
      " Train net_y2h: [epoch 406/500] train_loss:0.000004 Time:2.1351\n",
      "\n",
      " Train net_y2h: [epoch 407/500] train_loss:0.000003 Time:2.1399\n",
      "\n",
      " Train net_y2h: [epoch 408/500] train_loss:0.000002 Time:2.1448\n",
      "\n",
      " Train net_y2h: [epoch 409/500] train_loss:0.000008 Time:2.1496\n",
      "\n",
      " Train net_y2h: [epoch 410/500] train_loss:0.000008 Time:2.1545\n",
      "\n",
      " Train net_y2h: [epoch 411/500] train_loss:0.000003 Time:2.1594\n",
      "\n",
      " Train net_y2h: [epoch 412/500] train_loss:0.000002 Time:2.1642\n",
      "\n",
      " Train net_y2h: [epoch 413/500] train_loss:0.000003 Time:2.1691\n",
      "\n",
      " Train net_y2h: [epoch 414/500] train_loss:0.000003 Time:2.1741\n",
      "\n",
      " Train net_y2h: [epoch 415/500] train_loss:0.000010 Time:2.1790\n",
      "\n",
      " Train net_y2h: [epoch 416/500] train_loss:0.000007 Time:2.1840\n",
      "\n",
      " Train net_y2h: [epoch 417/500] train_loss:0.000003 Time:2.1889\n",
      "\n",
      " Train net_y2h: [epoch 418/500] train_loss:0.000003 Time:2.1937\n",
      "\n",
      " Train net_y2h: [epoch 419/500] train_loss:0.000002 Time:2.1986\n",
      "\n",
      " Train net_y2h: [epoch 420/500] train_loss:0.000008 Time:2.2034\n",
      "\n",
      " Train net_y2h: [epoch 421/500] train_loss:0.000003 Time:2.2083\n",
      "\n",
      " Train net_y2h: [epoch 422/500] train_loss:0.000003 Time:2.2132\n",
      "\n",
      " Train net_y2h: [epoch 423/500] train_loss:0.000003 Time:2.2181\n",
      "\n",
      " Train net_y2h: [epoch 424/500] train_loss:0.000003 Time:2.2230\n",
      "\n",
      " Train net_y2h: [epoch 425/500] train_loss:0.000004 Time:2.2278\n",
      "\n",
      " Train net_y2h: [epoch 426/500] train_loss:0.000003 Time:2.2327\n",
      "\n",
      " Train net_y2h: [epoch 427/500] train_loss:0.000010 Time:2.2379\n",
      "\n",
      " Train net_y2h: [epoch 428/500] train_loss:0.000007 Time:2.2432\n",
      "\n",
      " Train net_y2h: [epoch 429/500] train_loss:0.000007 Time:2.2481\n",
      "\n",
      " Train net_y2h: [epoch 430/500] train_loss:0.000004 Time:2.2532\n",
      "\n",
      " Train net_y2h: [epoch 431/500] train_loss:0.000003 Time:2.2581\n",
      "\n",
      " Train net_y2h: [epoch 432/500] train_loss:0.000006 Time:2.2631\n",
      "\n",
      " Train net_y2h: [epoch 433/500] train_loss:0.000009 Time:2.2682\n",
      "\n",
      " Train net_y2h: [epoch 434/500] train_loss:0.000003 Time:2.2731\n",
      "\n",
      " Train net_y2h: [epoch 435/500] train_loss:0.000003 Time:2.2781\n",
      "\n",
      " Train net_y2h: [epoch 436/500] train_loss:0.000007 Time:2.2829\n",
      "\n",
      " Train net_y2h: [epoch 437/500] train_loss:0.000004 Time:2.2878\n",
      "\n",
      " Train net_y2h: [epoch 438/500] train_loss:0.000011 Time:2.2927\n",
      "\n",
      " Train net_y2h: [epoch 439/500] train_loss:0.000009 Time:2.2976\n",
      "\n",
      " Train net_y2h: [epoch 440/500] train_loss:0.000011 Time:2.3025\n",
      "\n",
      " Train net_y2h: [epoch 441/500] train_loss:0.000011 Time:2.3073\n",
      "\n",
      " Train net_y2h: [epoch 442/500] train_loss:0.000002 Time:2.3122\n",
      "\n",
      " Train net_y2h: [epoch 443/500] train_loss:0.000005 Time:2.3171\n",
      "\n",
      " Train net_y2h: [epoch 444/500] train_loss:0.000007 Time:2.3220\n",
      "\n",
      " Train net_y2h: [epoch 445/500] train_loss:0.000008 Time:2.3268\n",
      "\n",
      " Train net_y2h: [epoch 446/500] train_loss:0.000007 Time:2.3317\n",
      "\n",
      " Train net_y2h: [epoch 447/500] train_loss:0.000003 Time:2.3365\n",
      "\n",
      " Train net_y2h: [epoch 448/500] train_loss:0.000004 Time:2.3414\n",
      "\n",
      " Train net_y2h: [epoch 449/500] train_loss:0.000003 Time:2.3461\n",
      "\n",
      " Train net_y2h: [epoch 450/500] train_loss:0.000008 Time:2.3510\n",
      "\n",
      " Train net_y2h: [epoch 451/500] train_loss:0.000003 Time:2.3558\n",
      "\n",
      " Train net_y2h: [epoch 452/500] train_loss:0.000003 Time:2.3607\n",
      "\n",
      " Train net_y2h: [epoch 453/500] train_loss:0.000007 Time:2.3655\n",
      "\n",
      " Train net_y2h: [epoch 454/500] train_loss:0.000004 Time:2.3704\n",
      "\n",
      " Train net_y2h: [epoch 455/500] train_loss:0.000004 Time:2.3752\n",
      "\n",
      " Train net_y2h: [epoch 456/500] train_loss:0.000006 Time:2.3800\n",
      "\n",
      " Train net_y2h: [epoch 457/500] train_loss:0.000003 Time:2.3848\n",
      "\n",
      " Train net_y2h: [epoch 458/500] train_loss:0.000007 Time:2.3897\n",
      "\n",
      " Train net_y2h: [epoch 459/500] train_loss:0.000003 Time:2.3946\n",
      "\n",
      " Train net_y2h: [epoch 460/500] train_loss:0.000003 Time:2.3994\n",
      "\n",
      " Train net_y2h: [epoch 461/500] train_loss:0.000005 Time:2.4043\n",
      "\n",
      " Train net_y2h: [epoch 462/500] train_loss:0.000010 Time:2.4091\n",
      "\n",
      " Train net_y2h: [epoch 463/500] train_loss:0.000003 Time:2.4140\n",
      "\n",
      " Train net_y2h: [epoch 464/500] train_loss:0.000006 Time:2.4188\n",
      "\n",
      " Train net_y2h: [epoch 465/500] train_loss:0.000001 Time:2.4237\n",
      "\n",
      " Train net_y2h: [epoch 466/500] train_loss:0.000007 Time:2.4285\n",
      "\n",
      " Train net_y2h: [epoch 467/500] train_loss:0.000008 Time:2.4334\n",
      "\n",
      " Train net_y2h: [epoch 468/500] train_loss:0.000010 Time:2.4387\n",
      "\n",
      " Train net_y2h: [epoch 469/500] train_loss:0.000004 Time:2.4442\n",
      "\n",
      " Train net_y2h: [epoch 470/500] train_loss:0.000004 Time:2.4493\n",
      "\n",
      " Train net_y2h: [epoch 471/500] train_loss:0.000003 Time:2.4544\n",
      "\n",
      " Train net_y2h: [epoch 472/500] train_loss:0.000003 Time:2.4594\n",
      "\n",
      " Train net_y2h: [epoch 473/500] train_loss:0.000008 Time:2.4644\n",
      "\n",
      " Train net_y2h: [epoch 474/500] train_loss:0.000003 Time:2.4693\n",
      "\n",
      " Train net_y2h: [epoch 475/500] train_loss:0.000009 Time:2.4742\n",
      "\n",
      " Train net_y2h: [epoch 476/500] train_loss:0.000002 Time:2.4791\n",
      "\n",
      " Train net_y2h: [epoch 477/500] train_loss:0.000007 Time:2.4840\n",
      "\n",
      " Train net_y2h: [epoch 478/500] train_loss:0.000007 Time:2.4888\n",
      "\n",
      " Train net_y2h: [epoch 479/500] train_loss:0.000011 Time:2.4937\n",
      "\n",
      " Train net_y2h: [epoch 480/500] train_loss:0.000010 Time:2.4986\n",
      "\n",
      " Train net_y2h: [epoch 481/500] train_loss:0.000002 Time:2.5035\n",
      "\n",
      " Train net_y2h: [epoch 482/500] train_loss:0.000006 Time:2.5097\n",
      "\n",
      " Train net_y2h: [epoch 483/500] train_loss:0.000002 Time:2.5176\n",
      "\n",
      " Train net_y2h: [epoch 484/500] train_loss:0.000004 Time:2.5249\n",
      "\n",
      " Train net_y2h: [epoch 485/500] train_loss:0.000005 Time:2.5322\n",
      "\n",
      " Train net_y2h: [epoch 486/500] train_loss:0.000002 Time:2.5393\n",
      "\n",
      " Train net_y2h: [epoch 487/500] train_loss:0.000005 Time:2.5464\n",
      "\n",
      " Train net_y2h: [epoch 488/500] train_loss:0.000004 Time:2.5538\n",
      "\n",
      " Train net_y2h: [epoch 489/500] train_loss:0.000007 Time:2.5613\n",
      "\n",
      " Train net_y2h: [epoch 490/500] train_loss:0.000008 Time:2.5687\n",
      "\n",
      " Train net_y2h: [epoch 491/500] train_loss:0.000011 Time:2.5760\n",
      "\n",
      " Train net_y2h: [epoch 492/500] train_loss:0.000003 Time:2.5834\n",
      "\n",
      " Train net_y2h: [epoch 493/500] train_loss:0.000004 Time:2.5907\n",
      "\n",
      " Train net_y2h: [epoch 494/500] train_loss:0.000009 Time:2.5984\n",
      "\n",
      " Train net_y2h: [epoch 495/500] train_loss:0.000002 Time:2.6051\n",
      "\n",
      " Train net_y2h: [epoch 496/500] train_loss:0.000002 Time:2.6127\n",
      "\n",
      " Train net_y2h: [epoch 497/500] train_loss:0.000003 Time:2.6211\n",
      "\n",
      " Train net_y2h: [epoch 498/500] train_loss:0.000008 Time:2.6291\n",
      "\n",
      " Train net_y2h: [epoch 499/500] train_loss:0.000005 Time:2.6372\n",
      "\n",
      " Train net_y2h: [epoch 500/500] train_loss:0.000004 Time:2.6436\n",
      "\n",
      " labels vs reconstructed labels\n",
      "[[0.64078593 0.63993657]\n",
      " [0.51509726 0.5154856 ]\n",
      " [0.75351596 0.7542075 ]\n",
      " [0.2550584  0.25553352]\n",
      " [0.7598881  0.7604561 ]\n",
      " [0.78339535 0.7834733 ]\n",
      " [0.25949243 0.25986147]\n",
      " [0.6846514  0.68483996]\n",
      " [0.64459467 0.6441041 ]\n",
      " [0.9795517  0.9788022 ]]\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "'''               Pre-trained CNN and GAN for label embedding                       '''\n",
    "#######################################################################################\n",
    "if args.GAN == \"CcGAN\":\n",
    "    net_embed_filename_ckpt = os.path.join(path_to_embed_models, 'ckpt_{}_epoch_{}_seed_{}.pth'.format(args.net_embed, args.epoch_cnn_embed, args.seed))\n",
    "    net_y2h_filename_ckpt = os.path.join(path_to_embed_models, 'ckpt_net_y2h_epoch_{}_seed_{}.pth'.format(args.epoch_net_y2h, args.seed))\n",
    "\n",
    "    print(\"\\n \"+net_embed_filename_ckpt)\n",
    "    print(\"\\n \"+net_y2h_filename_ckpt)\n",
    "\n",
    "    trainset = IMGs_dataset(images_train, labels_train, normalize=True)\n",
    "    trainloader_embed_net = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size_embed, shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "    if args.net_embed == \"ResNet18_embed\":\n",
    "        net_embed = ResNet18_embed(dim_embed=args.dim_embed)\n",
    "    elif args.net_embed == \"ResNet34_embed\":\n",
    "        net_embed = ResNet34_embed(dim_embed=args.dim_embed)\n",
    "    elif args.net_embed == \"ResNet50_embed\":\n",
    "        net_embed = ResNet50_embed(dim_embed=args.dim_embed)\n",
    "    net_embed = net_embed.cuda()\n",
    "    net_embed = nn.DataParallel(net_embed)\n",
    "\n",
    "    net_y2h = model_y2h(dim_embed=args.dim_embed)\n",
    "    net_y2h = net_y2h.cuda()\n",
    "    net_y2h = nn.DataParallel(net_y2h)\n",
    "\n",
    "    ## (1). Train net_embed first: x2h+h2y\n",
    "    if not os.path.isfile(net_embed_filename_ckpt):\n",
    "        print(\"\\n Start training CNN for label embedding >>>\")\n",
    "        net_embed = train_net_embed(net=net_embed, net_name=args.net_embed, trainloader=trainloader_embed_net, testloader=None, epochs=args.epoch_cnn_embed, resume_epoch = args.resumeepoch_cnn_embed, lr_base=base_lr_x2y, lr_decay_factor=0.1, lr_decay_epochs=[80, 140], weight_decay=1e-4, path_to_ckpt = path_to_embed_models)\n",
    "        # save model\n",
    "        torch.save({\n",
    "        'net_state_dict': net_embed.state_dict(),\n",
    "        }, net_embed_filename_ckpt)\n",
    "    else:\n",
    "        print(\"\\n net_embed ckpt already exists\")\n",
    "        print(\"\\n Loading...\")\n",
    "        checkpoint = torch.load(net_embed_filename_ckpt)\n",
    "        net_embed.load_state_dict(checkpoint['net_state_dict'])\n",
    "    #end not os.path.isfile\n",
    "\n",
    "    ## (2). Train y2h\n",
    "    #train a net which maps a label back to the embedding space\n",
    "    if not os.path.isfile(net_y2h_filename_ckpt):\n",
    "        print(\"\\n Start training net_y2h >>>\")\n",
    "        net_y2h = train_net_y2h(unique_labels_norm, net_y2h, net_embed, epochs=args.epoch_net_y2h, lr_base=base_lr_y2h, lr_decay_factor=0.1, lr_decay_epochs=[150, 250, 350], weight_decay=1e-4, batch_size=128)\n",
    "        # save model\n",
    "        torch.save({\n",
    "        'net_state_dict': net_y2h.state_dict(),\n",
    "        }, net_y2h_filename_ckpt)\n",
    "    else:\n",
    "        print(\"\\n net_y2h ckpt already exists\")\n",
    "        print(\"\\n Loading...\")\n",
    "        checkpoint = torch.load(net_y2h_filename_ckpt)\n",
    "        net_y2h.load_state_dict(checkpoint['net_state_dict'])\n",
    "    #end not os.path.isfile\n",
    "\n",
    "    ##some simple test\n",
    "    indx_tmp = np.arange(len(unique_labels_norm))\n",
    "    np.random.shuffle(indx_tmp)\n",
    "    indx_tmp = indx_tmp[:10]\n",
    "    labels_tmp = unique_labels_norm[indx_tmp].reshape(-1,1)\n",
    "    labels_tmp = torch.from_numpy(labels_tmp).type(torch.float).cuda()\n",
    "    epsilons_tmp = np.random.normal(0, 0.2, len(labels_tmp))\n",
    "    epsilons_tmp = torch.from_numpy(epsilons_tmp).view(-1,1).type(torch.float).cuda()\n",
    "    labels_tmp = torch.clamp(labels_tmp+epsilons_tmp, 0.0, 1.0)\n",
    "    net_embed.eval()\n",
    "    net_h2y = net_embed.module.h2y\n",
    "    net_y2h.eval()\n",
    "    with torch.no_grad():\n",
    "        labels_rec_tmp = net_h2y(net_y2h(labels_tmp)).cpu().numpy().reshape(-1,1)\n",
    "    results = np.concatenate((labels_tmp.cpu().numpy(), labels_rec_tmp), axis=1)\n",
    "    print(\"\\n labels vs reconstructed labels\")\n",
    "    print(results)\n",
    "\n",
    "    #put models on cpu\n",
    "    net_embed = net_embed.cpu()\n",
    "    net_h2y = net_h2y.cpu()\n",
    "    del net_embed, net_h2y; gc.collect()\n",
    "    net_y2h = net_y2h.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d59c7",
   "metadata": {},
   "source": [
    "## Step 5 - GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3977967",
   "metadata": {},
   "source": [
    "First we get the `save_images_in_train_folder` dir and output some basic info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7acf6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CcGAN: SAGAN, soft, Sigma is 0.11059499831726932, Kappa is 128.44444444444406.\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "'''                                    GAN training                                 '''\n",
    "#######################################################################################\n",
    "if args.GAN == 'CcGAN':\n",
    "    print(\"CcGAN: {}, {}, Sigma is {}, Kappa is {}.\".format(args.GAN_arch, args.threshold_type, args.kernel_sigma, args.kappa))\n",
    "    save_images_in_train_folder = save_images_folder + '/{}_{}_{}_{}_in_train'.format(args.GAN_arch, args.threshold_type, args.kernel_sigma, args.kappa)\n",
    "elif args.GAN == \"cGAN\":\n",
    "    print(\"cGAN: {}, {} classes.\".format(args.GAN_arch, args.cGAN_num_classes))\n",
    "    save_images_in_train_folder = save_images_folder + '/{}_{}_in_train'.format(args.GAN_arch, args.cGAN_num_classes)\n",
    "elif args.GAN == \"cGAN-concat\":\n",
    "    print(\"cGAN-concat: {}.\".format(args.GAN_arch))\n",
    "    save_images_in_train_folder = save_images_folder + '/{}_in_train'.format(args.GAN_arch)\n",
    "os.makedirs(save_images_in_train_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26253a",
   "metadata": {},
   "source": [
    "Start the timer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e7db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Begin Training CcGAN:\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "print(\"\\n Begin Training %s:\" % args.GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374badc3",
   "metadata": {},
   "source": [
    "### Case 1 - `cGAN`\n",
    "\n",
    "If we are training `cGAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4f72759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training cGAN.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# cGAN: treated as a classification dataset\n",
    "if args.GAN != \"cGAN\":\n",
    "    print(\"Not training cGAN.\")\n",
    "    \n",
    "else:\n",
    "    Filename_GAN = save_models_folder + '/ckpt_{}_niters_{}_nDsteps_{}_nclass_{}_seed_{}.pth'.format(args.GAN_arch, args.niters_gan, args.num_D_steps, args.cGAN_num_classes, args.seed)\n",
    "    print(Filename_GAN)\n",
    "\n",
    "    if not os.path.isfile(Filename_GAN):\n",
    "        print(\"There are {} unique labels\".format(len(unique_labels)))\n",
    "\n",
    "        if args.GAN_arch==\"SAGAN\":\n",
    "            netG = cGAN_SAGAN_Generator(z_dim=args.dim_gan, num_classes=args.cGAN_num_classes)\n",
    "            netD = cGAN_SAGAN_Discriminator(num_classes=args.cGAN_num_classes)\n",
    "        else:\n",
    "            raise ValueError('Do not support!!!')\n",
    "        netG = nn.DataParallel(netG)\n",
    "        netD = nn.DataParallel(netD)\n",
    "\n",
    "        # Start training\n",
    "        netG, netD = train_cgan(images_train, labels_train, netG, netD, save_images_folder=save_images_in_train_folder, save_models_folder = save_models_folder)\n",
    "\n",
    "        # store model\n",
    "        torch.save({\n",
    "            'netG_state_dict': netG.state_dict(),\n",
    "        }, Filename_GAN)\n",
    "    else:\n",
    "        print(\"Loading pre-trained generator >>>\")\n",
    "        checkpoint = torch.load(Filename_GAN)\n",
    "        netG = cGAN_SAGAN_Generator(z_dim=args.dim_gan, num_classes=args.cGAN_num_classes).cuda()\n",
    "        netG = nn.DataParallel(netG)\n",
    "        netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "\n",
    "    # function for sampling from a trained GAN\n",
    "    def fn_sampleGAN_given_labels(labels, batch_size):\n",
    "        labels = labels * (args.max_label - args.min_label) + args.min_label\n",
    "        fake_images, fake_labels = sample_cgan_given_labels(netG, labels, class_cutoff_points=class_cutoff_points, batch_size = batch_size)\n",
    "        fake_labels = (fake_labels - args.min_label) / (args.max_label - args.min_label)\n",
    "        return fake_images, fake_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5c094",
   "metadata": {},
   "source": [
    "### Case 2 - `cGAN-concat`\n",
    "\n",
    "If we are training `cGAN-concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a64fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training cGAN-concat.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# cGAN: simple concatenation\n",
    "if args.GAN != \"cGAN-concat\":\n",
    "    print(\"Not training cGAN-concat.\")\n",
    "\n",
    "else:\n",
    "    Filename_GAN = save_models_folder + '/ckpt_{}_niters_{}_nDsteps_{}_seed_{}.pth'.format(args.GAN_arch, args.niters_gan, args.num_D_steps, args.seed)\n",
    "    print(Filename_GAN)\n",
    "\n",
    "    if not os.path.isfile(Filename_GAN):\n",
    "        if args.GAN_arch==\"SAGAN\":\n",
    "            netG = cGAN_concat_SAGAN_Generator(z_dim=args.dim_gan)\n",
    "            netD = cGAN_concat_SAGAN_Discriminator()\n",
    "        else:\n",
    "            raise ValueError('Do not support!!!')\n",
    "        netG = nn.DataParallel(netG)\n",
    "        netD = nn.DataParallel(netD)\n",
    "\n",
    "        # Start training\n",
    "        netG, netD = train_cgan_concat(images_train, labels_train, netG, netD, save_images_folder=save_images_in_train_folder, save_models_folder = save_models_folder)\n",
    "\n",
    "        # store model\n",
    "        torch.save({\n",
    "            'netG_state_dict': netG.state_dict(),\n",
    "        }, Filename_GAN)\n",
    "    else:\n",
    "        print(\"Loading pre-trained generator >>>\")\n",
    "        checkpoint = torch.load(Filename_GAN)\n",
    "        netG = cGAN_concat_SAGAN_Generator(z_dim=args.dim_gan).cuda()\n",
    "        netG = nn.DataParallel(netG)\n",
    "        netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "\n",
    "    # function for sampling from a trained GAN\n",
    "    def fn_sampleGAN_given_labels(labels, batch_size):\n",
    "        labels = labels * (args.max_label - args.min_label) + args.min_label\n",
    "        fake_images, fake_labels = sample_cgan_concat_given_labels(netG, labels, batch_size = batch_size, denorm=True, to_numpy=True, verbose=True)\n",
    "        fake_labels = (fake_labels - args.min_label) / (args.max_label - args.min_label)\n",
    "        return fake_images, fake_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452216b",
   "metadata": {},
   "source": [
    "### Case 3 - `CcGAN`\n",
    "\n",
    "If we are training `CcGAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe4284b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Desktop/Myosotis-CcGAN/codes/main/output/output_CcGAN_arch_SAGAN/saved_models/ckpt_SAGAN_niters_30000_nDsteps_2_seed_42_soft_0.11059499831726932_128.44444444444406.pth\n",
      "[0.04866176 0.04866176 0.04866176 0.04866176 0.04866176 0.04866176\n",
      " 0.04866176 0.04866176 0.04866176 0.04866176 0.14851634 0.14851634\n",
      " 0.14851634 0.14851634 0.14851634 0.14851634 0.14851634 0.14851634\n",
      " 0.14851634 0.14851634 0.24837092 0.24837092 0.24837092 0.24837092\n",
      " 0.24837092 0.24837092 0.24837092 0.24837092 0.24837092 0.24837092\n",
      " 0.34822549 0.34822549 0.34822549 0.34822549 0.34822549 0.34822549\n",
      " 0.34822549 0.34822549 0.34822549 0.34822549 0.44808007 0.44808007\n",
      " 0.44808007 0.44808007 0.44808007 0.44808007 0.44808007 0.44808007\n",
      " 0.44808007 0.44808007 0.54793464 0.54793464 0.54793464 0.54793464\n",
      " 0.54793464 0.54793464 0.54793464 0.54793464 0.54793464 0.54793464\n",
      " 0.64778922 0.64778922 0.64778922 0.64778922 0.64778922 0.64778922\n",
      " 0.64778922 0.64778922 0.64778922 0.64778922 0.74764379 0.74764379\n",
      " 0.74764379 0.74764379 0.74764379 0.74764379 0.74764379 0.74764379\n",
      " 0.74764379 0.74764379 0.84749837 0.84749837 0.84749837 0.84749837\n",
      " 0.84749837 0.84749837 0.84749837 0.84749837 0.84749837 0.84749837\n",
      " 0.94735294 0.94735294 0.94735294 0.94735294 0.94735294 0.94735294\n",
      " 0.94735294 0.94735294 0.94735294 0.94735294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lib/python3.12/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/ubuntu/Desktop/Myosotis-CcGAN/codes/main/train_ccgan.py:246: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  loss_df = pd.concat([loss_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CcGAN,SAGAN: [Iter 20/30000] [D loss: 2.8530e-01] [G loss: 3.9638e+00] [real prob: 0.856] [fake prob: -3.062] [Time: 21.9980]\n",
      "CcGAN,SAGAN: [Iter 40/30000] [D loss: 3.9394e-01] [G loss: 7.2316e+00] [real prob: 0.979] [fake prob: -4.002] [Time: 43.7465]\n",
      "CcGAN,SAGAN: [Iter 60/30000] [D loss: 2.8993e-01] [G loss: 5.2975e+00] [real prob: 0.896] [fake prob: -1.488] [Time: 65.4939]\n",
      "CcGAN,SAGAN: [Iter 80/30000] [D loss: 6.5833e-01] [G loss: 4.6183e-01] [real prob: -0.216] [fake prob: -0.642] [Time: 87.2274]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m netD = nn.DataParallel(netD)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m netG, netD = \u001b[43mtrain_ccgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkernel_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_y2h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_images_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_images_in_train_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_models_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_models_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_outputs_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_to_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# store model\u001b[39;00m\n\u001b[32m     20\u001b[39m torch.save({\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnetG_state_dict\u001b[39m\u001b[33m'\u001b[39m: netG.state_dict(),\n\u001b[32m     22\u001b[39m }, Filename_GAN)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Myosotis-CcGAN/codes/main/train_ccgan.py:216\u001b[39m, in \u001b[36mtrain_ccgan\u001b[39m\u001b[34m(kernel_sigma, kappa, train_images, train_labels, netG, netD, net_y2h, save_images_folder, save_models_folder, save_outputs_folder, clip_label)\u001b[39m\n\u001b[32m    214\u001b[39m batch_epsilons = np.random.normal(\u001b[32m0\u001b[39m, kernel_sigma, batch_size_gene)\n\u001b[32m    215\u001b[39m batch_target_labels = batch_target_labels_in_dataset + batch_epsilons\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m batch_target_labels = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_target_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m z = torch.randn(batch_size_gene, dim_gan, dtype=torch.float).cuda()\n\u001b[32m    219\u001b[39m batch_fake_images = netG(z, net_y2h(batch_target_labels))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Concitnuous cGAN\n",
    "if args.GAN != \"CcGAN\":\n",
    "    print(\"Not training CcGAN.\")\n",
    "    \n",
    "else:\n",
    "    Filename_GAN = save_models_folder + '/ckpt_{}_niters_{}_nDsteps_{}_seed_{}_{}_{}_{}.pth'.format(args.GAN_arch, args.niters_gan, args.num_D_steps, args.seed, args.threshold_type, args.kernel_sigma, args.kappa)\n",
    "    print(Filename_GAN)\n",
    "\n",
    "    if not os.path.isfile(Filename_GAN):\n",
    "        netG = CcGAN_SAGAN_Generator(dim_z=args.dim_gan, dim_embed=args.dim_embed)\n",
    "        netD = CcGAN_SAGAN_Discriminator(dim_embed=args.dim_embed)\n",
    "        netG = nn.DataParallel(netG)\n",
    "        netD = nn.DataParallel(netD)\n",
    "\n",
    "        # Start training\n",
    "        netG, netD = train_ccgan(args.kernel_sigma, args.kappa, images_train, labels_train, netG, netD, net_y2h, save_images_folder=save_images_in_train_folder, save_models_folder = save_models_folder, save_outputs_folder=path_to_output)\n",
    "\n",
    "        # store model\n",
    "        torch.save({\n",
    "            'netG_state_dict': netG.state_dict(),\n",
    "        }, Filename_GAN)\n",
    "\n",
    "    else:\n",
    "        print(\"Loading pre-trained generator >>>\")\n",
    "        checkpoint = torch.load(Filename_GAN)\n",
    "        netG = CcGAN_SAGAN_Generator(dim_z=args.dim_gan, dim_embed=args.dim_embed).cuda()\n",
    "        netG = nn.DataParallel(netG)\n",
    "        netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "\n",
    "    def fn_sampleGAN_given_labels(labels, batch_size):\n",
    "        fake_images, fake_labels = sample_ccgan_given_labels(netG, net_y2h, labels, batch_size = batch_size, to_numpy=True, denorm=True, verbose=True)\n",
    "        return fake_images, fake_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31391f1b",
   "metadata": {},
   "source": [
    "End the timer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb947260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN training finished; Time elapses: 68.24979343700033s\n"
     ]
    }
   ],
   "source": [
    "stop = timeit.default_timer()\n",
    "print(\"GAN training finished; Time elapses: {}s\".format(stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f4c36",
   "metadata": {},
   "source": [
    "## Step 6 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation in Mode 2...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/Desktop/Ra/models/CcGAN_improved/output/eval_models/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m PreNetFID = nn.DataParallel(PreNetFID)\n\u001b[32m      9\u001b[39m Filename_PreCNNForEvalGANs = args.eval_ckpt_path + \u001b[33m'\u001b[39m\u001b[33m/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m checkpoint_PreNet = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFilename_PreCNNForEvalGANs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m PreNetFID.load_state_dict(checkpoint_PreNet[\u001b[33m'\u001b[39m\u001b[33mnet_encoder_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Diversity: entropy of predicted races within each eval center\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pytorch/lib/python3.12/site-packages/torch/serialization.py:1479\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1477\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1481\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1482\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1483\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1484\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pytorch/lib/python3.12/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pytorch/lib/python3.12/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/ubuntu/Desktop/Ra/models/CcGAN_improved/output/eval_models/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth'"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "'''                                  Evaluation                                     '''\n",
    "#######################################################################################\n",
    "if args.comp_FID:\n",
    "    print(\"\\n Evaluation in Mode {}...\".format(args.eval_mode))\n",
    "\n",
    "    PreNetFID = encoder(dim_bottleneck=512).cuda()\n",
    "    PreNetFID = nn.DataParallel(PreNetFID)\n",
    "    Filename_PreCNNForEvalGANs = args.eval_ckpt_path + '/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth'\n",
    "    checkpoint_PreNet = torch.load(Filename_PreCNNForEvalGANs)\n",
    "    PreNetFID.load_state_dict(checkpoint_PreNet['net_encoder_state_dict'])\n",
    "\n",
    "    # Diversity: entropy of predicted races within each eval center\n",
    "    PreNetDiversity = ResNet34_class_eval(num_classes=49, ngpu = torch.cuda.device_count()).cuda() #49 chair types\n",
    "    Filename_PreCNNForEvalGANs_Diversity = args.eval_ckpt_path + '/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth'\n",
    "    checkpoint_PreNet = torch.load(Filename_PreCNNForEvalGANs_Diversity)\n",
    "    PreNetDiversity.load_state_dict(checkpoint_PreNet['net_state_dict'])\n",
    "\n",
    "    # for LS\n",
    "    PreNetLS = ResNet34_regre_eval(ngpu = torch.cuda.device_count()).cuda()\n",
    "    Filename_PreCNNForEvalGANs_LS = args.eval_ckpt_path + '/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth'\n",
    "    checkpoint_PreNet = torch.load(Filename_PreCNNForEvalGANs_LS)\n",
    "    PreNetLS.load_state_dict(checkpoint_PreNet['net_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "    #####################\n",
    "    # generate nfake images\n",
    "    print(\"\\n Start sampling {} fake images per label from GAN >>>\".format(args.nfake_per_label))\n",
    "\n",
    "    if args.eval_mode == 1: #Mode 1: eval on unique labels used for GAN training\n",
    "        eval_labels = np.sort(np.array(list(set(labels_train_raw)))) #not normalized\n",
    "    elif args.eval_mode in [2, 3]: #Mode 2 and 3: eval on all unique labels in the dataset\n",
    "        eval_labels = np.sort(np.array(list(set(labels_all)))) #not normalized\n",
    "    else: #Mode 4: eval on a interval [min_label, max_label] with num_eval_labels labels\n",
    "        eval_labels = np.linspace(np.min(labels_all), np.max(labels_all), args.num_eval_labels) #not normalized\n",
    "\n",
    "    unique_eval_labels = list(set(eval_labels))\n",
    "    print(\"\\n There are {} unique eval labels.\".format(len(unique_eval_labels)))\n",
    "\n",
    "    eval_labels_norm = (eval_labels - args.min_label) / (args.max_label - args.min_label) # normalized\n",
    "\n",
    "    for i in range(len(eval_labels)):\n",
    "        curr_label = eval_labels_norm[i]\n",
    "        if i == 0:\n",
    "            fake_labels_assigned = np.ones(args.nfake_per_label)*curr_label\n",
    "        else:\n",
    "            fake_labels_assigned = np.concatenate((fake_labels_assigned, np.ones(args.nfake_per_label)*curr_label))\n",
    "    fake_images, _ = fn_sampleGAN_given_labels(fake_labels_assigned, args.samp_batch_size)\n",
    "    assert len(fake_images) == args.nfake_per_label*len(eval_labels)\n",
    "    assert len(fake_labels_assigned) == args.nfake_per_label*len(eval_labels)\n",
    "    assert fake_images.min()>=0 and fake_images.max()<=255.0\n",
    "\n",
    "    ## dump fake images for computing NIQE\n",
    "    if args.dump_fake_for_NIQE:\n",
    "        print(\"\\n Dumping fake images for NIQE...\")\n",
    "        dump_fake_images_folder = save_images_folder + '/fake_images_for_NIQE_nfake_{}'.format(len(fake_images))\n",
    "        os.makedirs(dump_fake_images_folder, exist_ok=True)\n",
    "        for i in tqdm(range(len(fake_images))):\n",
    "            label_i = fake_labels_assigned[i] * (args.max_label - args.min_label) + args.min_label # unnormalized\n",
    "            filename_i = dump_fake_images_folder + \"/{}_{}.png\".format(i, label_i)\n",
    "            os.makedirs(os.path.dirname(filename_i), exist_ok=True)\n",
    "            image_i = fake_images[i].astype(np.uint8)\n",
    "            # image_i = ((image_i*0.5+0.5)*255.0).astype(np.uint8)\n",
    "            image_i_pil = Image.fromarray(image_i.transpose(1,2,0))\n",
    "            image_i_pil.save(filename_i)\n",
    "        #end for i\n",
    "        # sys.exit()\n",
    "\n",
    "    print(\"End sampling! We got {} fake images.\".format(len(fake_images)))\n",
    "\n",
    "\n",
    "    #####################\n",
    "    # prepare real/fake images and labels\n",
    "    if args.eval_mode in [1, 3]:\n",
    "        # real_images = (images_train/255.0-0.5)/0.5\n",
    "        real_images = images_train\n",
    "        real_labels = labels_train_raw #not normalized\n",
    "    else: #for both mode 2 and 4\n",
    "        # real_images = (images_all/255.0-0.5)/0.5\n",
    "        real_images = images_all\n",
    "        real_labels = labels_all #not normalized\n",
    "    # fake_images = (fake_images/255.0-0.5)/0.5\n",
    "\n",
    "\n",
    "    #######################\n",
    "    # For each label take nreal_per_label images\n",
    "    unique_labels_real = np.sort(np.array(list(set(real_labels))))\n",
    "    indx_subset = []\n",
    "    for i in range(len(unique_labels_real)):\n",
    "        label_i = unique_labels_real[i]\n",
    "        indx_i = np.where(real_labels==label_i)[0]\n",
    "        np.random.shuffle(indx_i)\n",
    "        if args.nreal_per_label>1:\n",
    "            indx_i = indx_i[0:args.nreal_per_label]\n",
    "        indx_subset.append(indx_i)\n",
    "    indx_subset = np.concatenate(indx_subset)\n",
    "    real_images = real_images[indx_subset]\n",
    "    real_labels = real_labels[indx_subset]\n",
    "\n",
    "\n",
    "    nfake_all = len(fake_images)\n",
    "    nreal_all = len(real_images)\n",
    "\n",
    "\n",
    "    #####################\n",
    "    # Evaluate FID within a sliding window with a radius R on the label's range (not normalized range, i.e., [min_label,max_label]). The center of the sliding window locate on [min_label+R,...,max_label-R].\n",
    "    if args.eval_mode == 1:\n",
    "        center_start = np.min(labels_train_raw)+args.FID_radius ##bug???\n",
    "        center_stop = np.max(labels_train_raw)-args.FID_radius\n",
    "    else:\n",
    "        center_start = np.min(labels_all)+args.FID_radius\n",
    "        center_stop = np.max(labels_all)-args.FID_radius\n",
    "\n",
    "    if args.FID_num_centers<=0 and args.FID_radius==0: #completely overlap\n",
    "        centers_loc = eval_labels #not normalized\n",
    "    elif args.FID_num_centers>0:\n",
    "        centers_loc = np.linspace(center_start, center_stop, args.FID_num_centers) #not normalized\n",
    "    else:\n",
    "        print(\"\\n Error.\")\n",
    "    FID_over_centers = np.zeros(len(centers_loc))\n",
    "    entropies_over_centers = np.zeros(len(centers_loc)) # entropy at each center\n",
    "    labelscores_over_centers = np.zeros(len(centers_loc)) #label score at each center\n",
    "    num_realimgs_over_centers = np.zeros(len(centers_loc))\n",
    "    for i in range(len(centers_loc)):\n",
    "        center = centers_loc[i]\n",
    "        interval_start = (center - args.FID_radius)#/args.max_label\n",
    "        interval_stop = (center + args.FID_radius)#/args.max_label\n",
    "        indx_real = np.where((real_labels>=interval_start)*(real_labels<=interval_stop)==True)[0]\n",
    "        np.random.shuffle(indx_real)\n",
    "        real_images_curr = real_images[indx_real]\n",
    "        real_images_curr = (real_images_curr/255.0-0.5)/0.5\n",
    "        num_realimgs_over_centers[i] = len(real_images_curr)\n",
    "        indx_fake = np.where((fake_labels_assigned>=((interval_start - args.min_label)/(args.max_label - args.min_label)))*(fake_labels_assigned<=((interval_stop - args.min_label)/(args.max_label - args.min_label)))==True)[0]\n",
    "        np.random.shuffle(indx_fake)\n",
    "        fake_images_curr = fake_images[indx_fake]\n",
    "        fake_images_curr = (fake_images_curr/255.0-0.5)/0.5\n",
    "        fake_labels_assigned_curr = fake_labels_assigned[indx_fake]\n",
    "        # FID\n",
    "        FID_over_centers[i] = cal_FID(PreNetFID, real_images_curr, fake_images_curr, batch_size = 200, resize = None)\n",
    "        # Entropy of predicted class labels\n",
    "        predicted_class_labels = predict_class_labels(PreNetDiversity, fake_images_curr, batch_size=200, num_workers=args.num_workers)\n",
    "        entropies_over_centers[i] = compute_entropy(predicted_class_labels)\n",
    "        # Label score\n",
    "        labelscores_over_centers[i], _ = cal_labelscore(PreNetLS, fake_images_curr, fake_labels_assigned_curr, min_label_before_shift=0, max_label_after_shift=args.max_label, batch_size = 500, resize = None, num_workers=args.num_workers)\n",
    "\n",
    "        print(\"\\n [{}/{}] Center:{}; Real:{}; Fake:{}; FID:{}; LS:{}; ET:{}.\".format(i+1, len(centers_loc), center, len(real_images_curr), len(fake_images_curr), FID_over_centers[i], labelscores_over_centers[i], entropies_over_centers[i]))\n",
    "    # end for i\n",
    "    # average over all centers\n",
    "    print(\"\\n {} SFID: {}({}); min/max: {}/{}.\".format(args.GAN_arch, np.mean(FID_over_centers), np.std(FID_over_centers), np.min(FID_over_centers), np.max(FID_over_centers)))\n",
    "    print(\"\\n {} LS over centers: {}({}); min/max: {}/{}.\".format(args.GAN_arch, np.mean(labelscores_over_centers), np.std(labelscores_over_centers), np.min(labelscores_over_centers), np.max(labelscores_over_centers)))\n",
    "    print(\"\\n {} entropy over centers: {}({}); min/max: {}/{}.\".format(args.GAN_arch, np.mean(entropies_over_centers), np.std(entropies_over_centers), np.min(entropies_over_centers), np.max(entropies_over_centers)))\n",
    "\n",
    "\n",
    "    # dump FID versus number of samples (for each center) to npy\n",
    "    dump_fid_ls_entropy_over_centers_filename = os.path.join(path_to_output, 'fid_ls_entropy_over_centers')\n",
    "    np.savez(dump_fid_ls_entropy_over_centers_filename, fids=FID_over_centers, labelscores=labelscores_over_centers, entropies=entropies_over_centers, nrealimgs=num_realimgs_over_centers, centers=centers_loc)\n",
    "\n",
    "    #####################\n",
    "    # FID: Evaluate FID on all fake images\n",
    "    indx_shuffle_real = np.arange(nreal_all); np.random.shuffle(indx_shuffle_real)\n",
    "    indx_shuffle_fake = np.arange(nfake_all); np.random.shuffle(indx_shuffle_fake)\n",
    "    FID = cal_FID(PreNetFID, real_images[indx_shuffle_real], fake_images[indx_shuffle_fake], batch_size = 200, resize = None, norm_img = True)\n",
    "    print(\"\\n {}: FID of {} fake images: {}.\".format(args.GAN_arch, nfake_all, FID))\n",
    "\n",
    "    #####################\n",
    "    # Overall LS: abs(y_assigned - y_predicted)\n",
    "    ls_mean_overall, ls_std_overall = cal_labelscore(PreNetLS, fake_images, fake_labels_assigned, min_label_before_shift=0, max_label_after_shift=args.max_label, batch_size = 200, resize = None, norm_img = True, num_workers=args.num_workers)\n",
    "    print(\"\\n {}: overall LS of {} fake images: {}({}).\".format(args.GAN_arch, nfake_all, ls_mean_overall, ls_std_overall))\n",
    "\n",
    "\n",
    "    #####################\n",
    "    # Dump evaluation results\n",
    "    eval_results_logging_fullpath = os.path.join(path_to_output, 'eval_results_{}.txt'.format(args.GAN_arch))\n",
    "    if not os.path.isfile(eval_results_logging_fullpath):\n",
    "        eval_results_logging_file = open(eval_results_logging_fullpath, \"w\")\n",
    "        eval_results_logging_file.close()\n",
    "    with open(eval_results_logging_fullpath, 'a') as eval_results_logging_file:\n",
    "        eval_results_logging_file.write(\"\\n===================================================================================================\")\n",
    "        eval_results_logging_file.write(\"\\n Eval Mode: {}; Radius: {}; # Centers: {}.  \\n\".format(args.eval_mode, args.FID_radius, args.FID_num_centers))\n",
    "        print(args, file=eval_results_logging_file)\n",
    "        eval_results_logging_file.write(\"\\n SFID: {}({}).\".format(np.mean(FID_over_centers), np.std(FID_over_centers)))\n",
    "        eval_results_logging_file.write(\"\\n LS: {}({}).\".format(np.mean(labelscores_over_centers), np.std(labelscores_over_centers)))\n",
    "        eval_results_logging_file.write(\"\\n Diversity: {}({}).\".format(np.mean(entropies_over_centers), np.std(entropies_over_centers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f20d1",
   "metadata": {},
   "source": [
    "## Step 7 - Visualize Fake Images of the Trained GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d72572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "'''               Visualize fake images of the trained GAN                          '''\n",
    "#######################################################################################\n",
    "if args.visualize_fake_images:\n",
    "\n",
    "    # First, visualize conditional generation # vertical grid\n",
    "    ## 10 rows; 3 columns (3 samples for each age)\n",
    "    n_row = 10\n",
    "    n_col = 10\n",
    "\n",
    "    displayed_unique_labels = np.sort(np.array(list(set(labels_all))))\n",
    "    displayed_labels_indx = (np.linspace(0.05, 0.95, n_row)*len(displayed_unique_labels)).astype(int)\n",
    "    displayed_labels = displayed_unique_labels[displayed_labels_indx] #not normalized\n",
    "    displayed_normalized_labels = (displayed_labels - args.min_label)/(args.max_label - args.min_label) # normalized\n",
    "\n",
    "    ### output fake images from a trained GAN\n",
    "    filename_fake_images = os.path.join(save_images_folder, 'fake_images_grid_{}x{}.png').format(n_row, n_col)\n",
    "    fake_labels_assigned = []\n",
    "    for tmp_i in range(len(displayed_normalized_labels)):\n",
    "        curr_label = displayed_normalized_labels[tmp_i]\n",
    "        fake_labels_assigned.append(np.ones(shape=[n_col, 1])*curr_label)\n",
    "    fake_labels_assigned = np.concatenate(fake_labels_assigned, axis=0)\n",
    "    images_show, _ = fn_sampleGAN_given_labels(fake_labels_assigned, args.samp_batch_size)\n",
    "    images_show = (images_show/255.0-0.5)/0.5\n",
    "    images_show = torch.from_numpy(images_show)\n",
    "    save_image(images_show.data, filename_fake_images, nrow=n_col, normalize=True)\n",
    "\n",
    "\n",
    "    if args.GAN == \"CcGAN\":\n",
    "        # Second, fix z but increase y; check whether there is a continuous change, only for CcGAN\n",
    "        n_continuous_labels = 10\n",
    "        normalized_continuous_labels = np.linspace(0.05, 0.95, n_continuous_labels)\n",
    "        z = torch.randn(1, args.dim_gan, dtype=torch.float).cuda()\n",
    "        continuous_images_show = torch.zeros(n_continuous_labels, args.num_channels, args.img_size, args.img_size, dtype=torch.float)\n",
    "        netG.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_continuous_labels):\n",
    "                y = np.ones(1) * normalized_continuous_labels[i]\n",
    "                y = torch.from_numpy(y).type(torch.float).view(-1,1).cuda()\n",
    "                fake_image_i = netG(z, net_y2h(y))\n",
    "                continuous_images_show[i,:,:,:] = fake_image_i.cpu()\n",
    "        filename_continous_fake_images = os.path.join(save_images_folder, 'continuous_fake_images_grid.png')\n",
    "        save_image(continuous_images_show.data, filename_continous_fake_images, nrow=n_continuous_labels, normalize=True)\n",
    "        print(\"Continuous ys: \", (normalized_continuous_labels*(args.max_label - args.min_label) + args.min_label))\n",
    "\n",
    "\n",
    "    ### output some real images as baseline\n",
    "    filename_real_images = save_images_folder + '/real_images_grid_{}x{}.png'.format(n_row, n_col)\n",
    "    if not os.path.isfile(filename_real_images):\n",
    "        images_show = np.zeros((n_row*n_col, args.num_channels, args.img_size, args.img_size))\n",
    "        for i_row in range(n_row):\n",
    "            # generate 3 real images from each interval\n",
    "            curr_label = displayed_labels[i_row]\n",
    "            for j_col in range(n_col):\n",
    "                indx_curr_label = np.where(labels_all==curr_label)[0]\n",
    "                np.random.shuffle(indx_curr_label)\n",
    "                indx_curr_label = indx_curr_label[0]\n",
    "                images_show[i_row*n_col+j_col] = images_all[indx_curr_label]\n",
    "        #end for i_row\n",
    "        images_show = (images_show/255.0-0.5)/0.5\n",
    "        images_show = torch.from_numpy(images_show)\n",
    "        save_image(images_show.data, filename_real_images, nrow=n_col, normalize=True)\n",
    "\n",
    "\n",
    "print(\"\\n===================================================================================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
