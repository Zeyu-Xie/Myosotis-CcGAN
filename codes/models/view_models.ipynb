{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5a6881",
   "metadata": {},
   "source": [
    "# View Models\n",
    "\n",
    "This notebook is used for visualizing `.pth` file structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7e0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d56fa",
   "metadata": {},
   "source": [
    "The main function we use to inspect a `.pth` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63cbec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_pth_file(pth_path, max_tensor_elements=5, max_optimizer_params=3):\n",
    "    print(f\"üîç Inspecting file: {pth_path}\\n\")\n",
    "    data = torch.load(pth_path, map_location='cpu')\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        print(f\"[ROOT] Type: {type(data)} (not a dict)\")\n",
    "        return\n",
    "\n",
    "    print(\"üìÅ Top-level Keys and Types:\")\n",
    "    for key in data:\n",
    "        print(f\" - {key}: {type(data[key])}\")\n",
    "    print()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        print(f\"=== [{key}] ===\")\n",
    "        if isinstance(value, OrderedDict):\n",
    "            print(f\"‚û°Ô∏è  Detected state_dict with {len(value)} parameters.\")\n",
    "            for name, tensor in value.items():\n",
    "                print(f\"  - {name:50} | shape: {tuple(tensor.shape)} | dtype: {tensor.dtype}\")\n",
    "        elif isinstance(value, dict) and 'state' in value and 'param_groups' in value:\n",
    "            print(\"‚û°Ô∏è  Detected optimizer state_dict.\")\n",
    "            state = value['state']\n",
    "            print(f\"  Contains {len(state)} parameter entries.\")\n",
    "            for i, (param_id, param_state) in enumerate(state.items()):\n",
    "                if i >= max_optimizer_params:\n",
    "                    print(\"  ... (truncated)\")\n",
    "                    break\n",
    "                print(f\"  ‚ñ∂Ô∏è  Param ID: {param_id}\")\n",
    "                for subkey, subval in param_state.items():\n",
    "                    if isinstance(subval, torch.Tensor):\n",
    "                        shape_str = f\"shape={tuple(subval.shape)}\"\n",
    "                        val_preview = subval.flatten()[:max_tensor_elements].tolist()\n",
    "                        print(f\"    - {subkey}: {shape_str}, dtype={subval.dtype}, values={val_preview}\")\n",
    "                    else:\n",
    "                        print(f\"    - {subkey}: {subval}\")\n",
    "        elif isinstance(value, torch.Tensor):\n",
    "            print(f\"‚û°Ô∏è  Tensor | shape: {value.shape} | dtype: {value.dtype} | first values: {value.flatten()[:max_tensor_elements].tolist()}\")\n",
    "        else:\n",
    "            print(f\"‚û°Ô∏è  {type(value)} | preview: {str(value)[:100]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362e5f3",
   "metadata": {},
   "source": [
    "Write the `MODEL_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27322d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/home/ubuntu/Desktop/output_1/output_CcGAN_arch_SAGAN/saved_models/CcGAN_SAGAN_soft_nDsteps_2_checkpoint_intrain/CcGAN_checkpoint_niters_7500.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b9fc",
   "metadata": {},
   "source": [
    "Inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c8fa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Inspecting file: /home/ubuntu/Desktop/output_1/output_CcGAN_arch_SAGAN/saved_models/CcGAN_SAGAN_soft_nDsteps_2_checkpoint_intrain/CcGAN_checkpoint_niters_7500.pth\n",
      "\n",
      "üìÅ Top-level Keys and Types:\n",
      " - netG_state_dict: <class 'collections.OrderedDict'>\n",
      " - netD_state_dict: <class 'collections.OrderedDict'>\n",
      " - optimizerG_state_dict: <class 'dict'>\n",
      " - optimizerD_state_dict: <class 'dict'>\n",
      " - rng_state: <class 'torch.Tensor'>\n",
      "\n",
      "=== [netG_state_dict] ===\n",
      "‚û°Ô∏è  Detected state_dict with 140 parameters.\n",
      "  - module.snlinear0.bias                              | shape: (16384,) | dtype: torch.float32\n",
      "  - module.snlinear0.weight_orig                       | shape: (16384, 128) | dtype: torch.float32\n",
      "  - module.snlinear0.weight_u                          | shape: (16384,) | dtype: torch.float32\n",
      "  - module.snlinear0.weight_v                          | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.cond_bn1.bn.running_mean             | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.cond_bn1.bn.running_var              | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.cond_bn1.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block1.cond_bn1.embed_gamma.weight          | shape: (1024, 128) | dtype: torch.float32\n",
      "  - module.block1.cond_bn1.embed_beta.weight           | shape: (1024, 128) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.weight_orig                | shape: (1024, 1024, 3, 3) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.weight_v                   | shape: (9216,) | dtype: torch.float32\n",
      "  - module.block1.cond_bn2.bn.running_mean             | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.cond_bn2.bn.running_var              | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.cond_bn2.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block1.cond_bn2.embed_gamma.weight          | shape: (1024, 128) | dtype: torch.float32\n",
      "  - module.block1.cond_bn2.embed_beta.weight           | shape: (1024, 128) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.weight_orig                | shape: (1024, 1024, 3, 3) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.weight_v                   | shape: (9216,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.weight_orig                | shape: (1024, 1024, 1, 1) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.weight_v                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block2.cond_bn1.bn.running_mean             | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block2.cond_bn1.bn.running_var              | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block2.cond_bn1.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block2.cond_bn1.embed_gamma.weight          | shape: (1024, 128) | dtype: torch.float32\n",
      "  - module.block2.cond_bn1.embed_beta.weight           | shape: (1024, 128) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.bias                       | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.weight_orig                | shape: (512, 1024, 3, 3) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.weight_u                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.weight_v                   | shape: (9216,) | dtype: torch.float32\n",
      "  - module.block2.cond_bn2.bn.running_mean             | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.cond_bn2.bn.running_var              | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.cond_bn2.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block2.cond_bn2.embed_gamma.weight          | shape: (512, 128) | dtype: torch.float32\n",
      "  - module.block2.cond_bn2.embed_beta.weight           | shape: (512, 128) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.bias                       | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.weight_orig                | shape: (512, 512, 3, 3) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.weight_u                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.weight_v                   | shape: (4608,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.bias                       | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.weight_orig                | shape: (512, 1024, 1, 1) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.weight_u                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.weight_v                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block3.cond_bn1.bn.running_mean             | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.cond_bn1.bn.running_var              | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.cond_bn1.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block3.cond_bn1.embed_gamma.weight          | shape: (512, 128) | dtype: torch.float32\n",
      "  - module.block3.cond_bn1.embed_beta.weight           | shape: (512, 128) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.bias                       | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.weight_orig                | shape: (256, 512, 3, 3) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.weight_u                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.weight_v                   | shape: (4608,) | dtype: torch.float32\n",
      "  - module.block3.cond_bn2.bn.running_mean             | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.cond_bn2.bn.running_var              | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.cond_bn2.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block3.cond_bn2.embed_gamma.weight          | shape: (256, 128) | dtype: torch.float32\n",
      "  - module.block3.cond_bn2.embed_beta.weight           | shape: (256, 128) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.bias                       | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.weight_orig                | shape: (256, 256, 3, 3) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.weight_u                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.weight_v                   | shape: (2304,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.bias                       | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.weight_orig                | shape: (256, 512, 1, 1) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.weight_u                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.weight_v                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.self_attn.sigma                             | shape: (1,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.bias              | shape: (32,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.weight_orig       | shape: (32, 256, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.weight_u          | shape: (32,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.weight_v          | shape: (256,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.bias                | shape: (32,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.weight_orig         | shape: (32, 256, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.weight_u            | shape: (32,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.weight_v            | shape: (256,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.bias                  | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.weight_orig           | shape: (128, 256, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.weight_u              | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.weight_v              | shape: (256,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.bias               | shape: (256,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.weight_orig        | shape: (256, 128, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.weight_u           | shape: (256,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.weight_v           | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.cond_bn1.bn.running_mean             | shape: (256,) | dtype: torch.float32\n",
      "  - module.block4.cond_bn1.bn.running_var              | shape: (256,) | dtype: torch.float32\n",
      "  - module.block4.cond_bn1.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block4.cond_bn1.embed_gamma.weight          | shape: (256, 128) | dtype: torch.float32\n",
      "  - module.block4.cond_bn1.embed_beta.weight           | shape: (256, 128) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.bias                       | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.weight_orig                | shape: (128, 256, 3, 3) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.weight_u                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.weight_v                   | shape: (2304,) | dtype: torch.float32\n",
      "  - module.block4.cond_bn2.bn.running_mean             | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.cond_bn2.bn.running_var              | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.cond_bn2.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block4.cond_bn2.embed_gamma.weight          | shape: (128, 128) | dtype: torch.float32\n",
      "  - module.block4.cond_bn2.embed_beta.weight           | shape: (128, 128) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.bias                       | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.weight_orig                | shape: (128, 128, 3, 3) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.weight_u                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.weight_v                   | shape: (1152,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.bias                       | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.weight_orig                | shape: (128, 256, 1, 1) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.weight_u                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.weight_v                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block5.cond_bn1.bn.running_mean             | shape: (128,) | dtype: torch.float32\n",
      "  - module.block5.cond_bn1.bn.running_var              | shape: (128,) | dtype: torch.float32\n",
      "  - module.block5.cond_bn1.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block5.cond_bn1.embed_gamma.weight          | shape: (128, 128) | dtype: torch.float32\n",
      "  - module.block5.cond_bn1.embed_beta.weight           | shape: (128, 128) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.bias                       | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.weight_orig                | shape: (64, 128, 3, 3) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.weight_u                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.weight_v                   | shape: (1152,) | dtype: torch.float32\n",
      "  - module.block5.cond_bn2.bn.running_mean             | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.cond_bn2.bn.running_var              | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.cond_bn2.bn.num_batches_tracked      | shape: () | dtype: torch.int64\n",
      "  - module.block5.cond_bn2.embed_gamma.weight          | shape: (64, 128) | dtype: torch.float32\n",
      "  - module.block5.cond_bn2.embed_beta.weight           | shape: (64, 128) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.bias                       | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.weight_orig                | shape: (64, 64, 3, 3) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.weight_u                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.weight_v                   | shape: (576,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.bias                       | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.weight_orig                | shape: (64, 128, 1, 1) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.weight_u                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.weight_v                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.bn.weight                                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.bn.bias                                     | shape: (64,) | dtype: torch.float32\n",
      "  - module.bn.running_mean                             | shape: (64,) | dtype: torch.float32\n",
      "  - module.bn.running_var                              | shape: (64,) | dtype: torch.float32\n",
      "  - module.bn.num_batches_tracked                      | shape: () | dtype: torch.int64\n",
      "  - module.snconv2d1.bias                              | shape: (3,) | dtype: torch.float32\n",
      "  - module.snconv2d1.weight_orig                       | shape: (3, 64, 3, 3) | dtype: torch.float32\n",
      "  - module.snconv2d1.weight_u                          | shape: (3,) | dtype: torch.float32\n",
      "  - module.snconv2d1.weight_v                          | shape: (576,) | dtype: torch.float32\n",
      "\n",
      "=== [netD_state_dict] ===\n",
      "‚û°Ô∏è  Detected state_dict with 96 parameters.\n",
      "  - module.opt_block1.snconv2d1.bias                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d1.weight_orig            | shape: (64, 3, 3, 3) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d1.weight_u               | shape: (64,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d1.weight_v               | shape: (27,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d2.bias                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d2.weight_orig            | shape: (64, 64, 3, 3) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d2.weight_u               | shape: (64,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d2.weight_v               | shape: (576,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d0.bias                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d0.weight_orig            | shape: (64, 3, 1, 1) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d0.weight_u               | shape: (64,) | dtype: torch.float32\n",
      "  - module.opt_block1.snconv2d0.weight_v               | shape: (3,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.bias                       | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.weight_orig                | shape: (128, 64, 3, 3) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.weight_u                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d1.weight_v                   | shape: (576,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.bias                       | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.weight_orig                | shape: (128, 128, 3, 3) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.weight_u                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d2.weight_v                   | shape: (1152,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.bias                       | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.weight_orig                | shape: (128, 64, 1, 1) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.weight_u                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block1.snconv2d0.weight_v                   | shape: (64,) | dtype: torch.float32\n",
      "  - module.self_attn.sigma                             | shape: (1,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.bias              | shape: (16,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.weight_orig       | shape: (16, 128, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.weight_u          | shape: (16,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_theta.weight_v          | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.bias                | shape: (16,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.weight_orig         | shape: (16, 128, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.weight_u            | shape: (16,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_phi.weight_v            | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.bias                  | shape: (64,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.weight_orig           | shape: (64, 128, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.weight_u              | shape: (64,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_g.weight_v              | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.bias               | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.weight_orig        | shape: (128, 64, 1, 1) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.weight_u           | shape: (128,) | dtype: torch.float32\n",
      "  - module.self_attn.snconv1x1_attn.weight_v           | shape: (64,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.bias                       | shape: (256,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.weight_orig                | shape: (256, 128, 3, 3) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.weight_u                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d1.weight_v                   | shape: (1152,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.bias                       | shape: (256,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.weight_orig                | shape: (256, 256, 3, 3) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.weight_u                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d2.weight_v                   | shape: (2304,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.bias                       | shape: (256,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.weight_orig                | shape: (256, 128, 1, 1) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.weight_u                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block2.snconv2d0.weight_v                   | shape: (128,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.bias                       | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.weight_orig                | shape: (512, 256, 3, 3) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.weight_u                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d1.weight_v                   | shape: (2304,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.bias                       | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.weight_orig                | shape: (512, 512, 3, 3) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.weight_u                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d2.weight_v                   | shape: (4608,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.bias                       | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.weight_orig                | shape: (512, 256, 1, 1) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.weight_u                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block3.snconv2d0.weight_v                   | shape: (256,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.weight_orig                | shape: (1024, 512, 3, 3) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d1.weight_v                   | shape: (4608,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.weight_orig                | shape: (1024, 1024, 3, 3) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d2.weight_v                   | shape: (9216,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.weight_orig                | shape: (1024, 512, 1, 1) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block4.snconv2d0.weight_v                   | shape: (512,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.weight_orig                | shape: (1024, 1024, 3, 3) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d1.weight_v                   | shape: (9216,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.weight_orig                | shape: (1024, 1024, 3, 3) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d2.weight_v                   | shape: (9216,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.bias                       | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.weight_orig                | shape: (1024, 1024, 1, 1) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.weight_u                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.block5.snconv2d0.weight_v                   | shape: (1024,) | dtype: torch.float32\n",
      "  - module.snlinear1.bias                              | shape: (1,) | dtype: torch.float32\n",
      "  - module.snlinear1.weight_orig                       | shape: (1, 16384) | dtype: torch.float32\n",
      "  - module.snlinear1.weight_u                          | shape: (1,) | dtype: torch.float32\n",
      "  - module.snlinear1.weight_v                          | shape: (16384,) | dtype: torch.float32\n",
      "  - module.sn_embedding1.weight_orig                   | shape: (16384, 128) | dtype: torch.float32\n",
      "  - module.sn_embedding1.weight_u                      | shape: (16384,) | dtype: torch.float32\n",
      "  - module.sn_embedding1.weight_v                      | shape: (128,) | dtype: torch.float32\n",
      "\n",
      "=== [optimizerG_state_dict] ===\n",
      "‚û°Ô∏è  Detected optimizer state_dict.\n",
      "  Contains 65 parameter entries.\n",
      "  ‚ñ∂Ô∏è  Param ID: 0\n",
      "    - step: shape=(), dtype=torch.float32, values=[7500.0]\n",
      "    - exp_avg: shape=(16384,), dtype=torch.float32, values=[0.0004266638425178826, 0.0011409034486860037, -0.0006328101735562086, -0.0008875222411006689, -0.0006528797093778849]\n",
      "    - exp_avg_sq: shape=(16384,), dtype=torch.float32, values=[1.3156330851415987e-06, 3.179099394401419e-06, 1.7579319546712213e-06, 1.3218386811786331e-06, 1.010470782603079e-06]\n",
      "  ‚ñ∂Ô∏è  Param ID: 1\n",
      "    - step: shape=(), dtype=torch.float32, values=[7500.0]\n",
      "    - exp_avg: shape=(16384, 128), dtype=torch.float32, values=[0.0003107140655629337, 8.874993363860995e-05, 0.00013471586862578988, 0.000134061963763088, 0.00014928345626685768]\n",
      "    - exp_avg_sq: shape=(16384, 128), dtype=torch.float32, values=[7.466895368679616e-08, 7.225077069961117e-08, 6.832486576513475e-08, 7.605526519682826e-08, 7.041152372266879e-08]\n",
      "  ‚ñ∂Ô∏è  Param ID: 2\n",
      "    - step: shape=(), dtype=torch.float32, values=[7500.0]\n",
      "    - exp_avg: shape=(1024, 128), dtype=torch.float32, values=[-0.00015185712254606187, 0.0, -1.2530410867992514e-41, -0.00017187766206916422, 0.0]\n",
      "    - exp_avg_sq: shape=(1024, 128), dtype=torch.float32, values=[5.838261873947204e-09, 0.0, 4.3408016561949337e-16, 6.555031628607821e-09, 0.0]\n",
      "  ... (truncated)\n",
      "\n",
      "=== [optimizerD_state_dict] ===\n",
      "‚û°Ô∏è  Detected optimizer state_dict.\n",
      "  Contains 46 parameter entries.\n",
      "  ‚ñ∂Ô∏è  Param ID: 0\n",
      "    - step: shape=(), dtype=torch.float32, values=[15000.0]\n",
      "    - exp_avg: shape=(64,), dtype=torch.float32, values=[-0.003460478037595749, 0.004136840812861919, 0.008868588134646416, -0.024798307567834854, 0.02321975864470005]\n",
      "    - exp_avg_sq: shape=(64,), dtype=torch.float32, values=[0.0002788723213598132, 0.00010499657946638763, 0.0010191811015829444, 0.0009865526808425784, 0.0053092860616743565]\n",
      "  ‚ñ∂Ô∏è  Param ID: 1\n",
      "    - step: shape=(), dtype=torch.float32, values=[15000.0]\n",
      "    - exp_avg: shape=(64, 3, 3, 3), dtype=torch.float32, values=[0.005671728402376175, 0.006083613261580467, 0.005228029564023018, 0.006805632263422012, 0.006646207068115473]\n",
      "    - exp_avg_sq: shape=(64, 3, 3, 3), dtype=torch.float32, values=[0.00031143694650381804, 0.0003076618886552751, 0.0003095782012678683, 0.0003223353123757988, 0.0003208084381185472]\n",
      "  ‚ñ∂Ô∏è  Param ID: 2\n",
      "    - step: shape=(), dtype=torch.float32, values=[15000.0]\n",
      "    - exp_avg: shape=(64,), dtype=torch.float32, values=[-0.026845339685678482, 0.021610694006085396, -0.01141605619341135, 0.015263672918081284, -0.006280107423663139]\n",
      "    - exp_avg_sq: shape=(64,), dtype=torch.float32, values=[0.0016451110132038593, 0.0009121574694290757, 0.0005069643375463784, 0.0023702720645815134, 0.0001817390730138868]\n",
      "  ... (truncated)\n",
      "\n",
      "=== [rng_state] ===\n",
      "‚û°Ô∏è  Tensor | shape: torch.Size([5056]) | dtype: torch.uint8 | first values: [228, 7, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_pth_file(MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
